SLURM Job ID: 20038024
directory /home/rgg2706/Multimodal-Sentiment-Analysis/OpinionMining/Datasets exists
directory /home/rgg2706/Multimodal-Sentiment-Analysis/Models/MOASC2/SaveFiles exists
TensorBoard logs will be saved to: /tmp/run_project_logs
Error loading image /home/rgg2706/Multimodal-Sentiment-Analysis/Datasets/MVSA_Multiple2/images/3149.jpg: cannot identify image file '/home/rgg2706/Multimodal-Sentiment-Analysis/Datasets/MVSA_Multiple2/images/3149.jpg'
Error loading image /home/rgg2706/Multimodal-Sentiment-Analysis/Datasets/MVSA_Multiple2/images/12244.jpg: image file is truncated (4 bytes not processed)
Error loading image /home/rgg2706/Multimodal-Sentiment-Analysis/Datasets/MVSA_Multiple2/images/1337.jpg: cannot identify image file '/home/rgg2706/Multimodal-Sentiment-Analysis/Datasets/MVSA_Multiple2/images/1337.jpg'

=== DATASET DEBUG INFO ===
Dataset name: MVSA_Multiple2
Train set size: 14274
Val set size: 1587
Test set size: 1763
Max text length: 23

[Sample of training data]
  Index 0 ID => text: 'knocked doors with the venerable  team trudeau lpc candidate kylejpeterson this aft in my hometown  aurora! elxn'
              label: 2
  Index 1 ID => text: 'canvassing for  elect kelly yeg yegfed elxn'
              label: 1
  Index 2 ID => text: 'i think it is time for change   ana  commit to  vote  generation trudeau  sfu lpc elxn http annoyedorhesitantt.cohvo i ud x ib'
              label: 2
========================


>>> Epoch 1/40
    Iteration 20, Loss: 1.0965, Acc: 37.50%
    Iteration 40, Loss: 1.1023, Acc: 37.50%
    Iteration 60, Loss: 1.1037, Acc: 37.50%
    Iteration 80, Loss: 1.1024, Acc: 28.12%
    Iteration 100, Loss: 1.0996, Acc: 28.12%
    Iteration 120, Loss: 1.0973, Acc: 78.12%
    Iteration 140, Loss: 1.0959, Acc: 37.50%
    Iteration 160, Loss: 1.1044, Acc: 34.38%
    Iteration 180, Loss: 1.1058, Acc: 50.00%
    Iteration 200, Loss: 1.0988, Acc: 37.50%
    Iteration 220, Loss: 1.0984, Acc: 25.00%
    Iteration 240, Loss: 1.0931, Acc: 46.88%
    Iteration 260, Loss: 1.0945, Acc: 34.38%
    Iteration 280, Loss: 1.1043, Acc: 21.88%
    Iteration 300, Loss: 1.1016, Acc: 15.62%
    Iteration 320, Loss: 1.0983, Acc: 43.75%
    Iteration 340, Loss: 1.1020, Acc: 34.38%
    Iteration 360, Loss: 1.0991, Acc: 37.50%
    Iteration 380, Loss: 1.1015, Acc: 25.00%
    Iteration 400, Loss: 1.0890, Acc: 43.75%
    Iteration 420, Loss: 1.1046, Acc: 25.00%
Epoch 1 complete. Train Loss: 1.0991, Val Loss: 1.0959, Val Acc: 39.40%, Test Loss: 1.0965, Test Acc: 38.09%
  [*] New best val_acc = 0.3940
  [*] New best test_acc = 0.3809, saving model...
Epoch time: 62.45s

>>> Epoch 2/40
    Iteration 20, Loss: 1.1045, Acc: 28.12%
    Iteration 40, Loss: 1.0942, Acc: 43.75%
    Iteration 60, Loss: 1.1049, Acc: 37.50%
    Iteration 80, Loss: 1.0911, Acc: 40.62%
    Iteration 100, Loss: 1.1100, Acc: 18.75%
    Iteration 120, Loss: 1.0902, Acc: 78.12%
    Iteration 140, Loss: 1.1059, Acc: 31.25%
    Iteration 160, Loss: 1.1052, Acc: 37.50%
    Iteration 180, Loss: 1.1071, Acc: 43.75%
    Iteration 200, Loss: 1.0937, Acc: 43.75%
    Iteration 220, Loss: 1.0980, Acc: 43.75%
    Iteration 240, Loss: 1.1011, Acc: 25.00%
    Iteration 260, Loss: 1.0946, Acc: 37.50%
    Iteration 280, Loss: 1.0938, Acc: 28.12%
    Iteration 300, Loss: 1.0960, Acc: 18.75%
    Iteration 320, Loss: 1.0945, Acc: 43.75%
    Iteration 340, Loss: 1.0960, Acc: 34.38%
    Iteration 360, Loss: 1.1008, Acc: 28.12%
    Iteration 380, Loss: 1.1048, Acc: 25.00%
    Iteration 400, Loss: 1.0981, Acc: 25.00%
    Iteration 420, Loss: 1.1040, Acc: 34.38%
Epoch 2 complete. Train Loss: 1.0987, Val Loss: 1.1020, Val Acc: 27.38%, Test Loss: 1.1025, Test Acc: 27.31%
Epoch time: 60.05s

>>> Epoch 3/40
    Iteration 20, Loss: 1.1014, Acc: 40.62%
    Iteration 40, Loss: 1.1019, Acc: 31.25%
    Iteration 60, Loss: 1.1075, Acc: 25.00%
    Iteration 80, Loss: 1.0971, Acc: 31.25%
    Iteration 100, Loss: 1.1021, Acc: 12.50%
    Iteration 120, Loss: 1.1048, Acc: 78.12%
    Iteration 140, Loss: 1.0985, Acc: 40.62%
    Iteration 160, Loss: 1.1008, Acc: 43.75%
    Iteration 180, Loss: 1.1005, Acc: 53.12%
    Iteration 200, Loss: 1.0929, Acc: 53.12%
    Iteration 220, Loss: 1.0941, Acc: 46.88%
    Iteration 240, Loss: 1.0874, Acc: 62.50%
    Iteration 260, Loss: 1.0927, Acc: 50.00%
    Iteration 280, Loss: 1.1026, Acc: 31.25%
    Iteration 300, Loss: 1.0966, Acc: 25.00%
    Iteration 320, Loss: 1.0999, Acc: 34.38%
    Iteration 340, Loss: 1.0883, Acc: 37.50%
    Iteration 360, Loss: 1.0930, Acc: 46.88%
    Iteration 380, Loss: 1.0960, Acc: 34.38%
    Iteration 400, Loss: 1.0945, Acc: 40.62%
    Iteration 420, Loss: 1.1019, Acc: 46.88%
Epoch 3 complete. Train Loss: 1.0980, Val Loss: 1.0985, Val Acc: 32.80%, Test Loss: 1.0990, Test Acc: 32.70%
Epoch time: 59.91s

>>> Epoch 4/40
    Iteration 20, Loss: 1.1051, Acc: 28.12%
    Iteration 40, Loss: 1.0913, Acc: 37.50%
    Iteration 60, Loss: 1.1129, Acc: 21.88%
    Iteration 80, Loss: 1.0999, Acc: 28.12%
    Iteration 100, Loss: 1.1025, Acc: 25.00%
    Iteration 120, Loss: 1.0738, Acc: 50.00%
    Iteration 140, Loss: 1.0940, Acc: 43.75%
    Iteration 160, Loss: 1.0975, Acc: 31.25%
    Iteration 180, Loss: 1.0938, Acc: 40.62%
    Iteration 200, Loss: 1.0963, Acc: 34.38%
    Iteration 220, Loss: 1.1029, Acc: 34.38%
    Iteration 240, Loss: 1.0828, Acc: 37.50%
    Iteration 260, Loss: 1.0937, Acc: 46.88%
    Iteration 280, Loss: 1.0925, Acc: 43.75%
    Iteration 300, Loss: 1.0770, Acc: 43.75%
    Iteration 320, Loss: 1.0982, Acc: 37.50%
    Iteration 340, Loss: 1.0887, Acc: 43.75%
    Iteration 360, Loss: 1.0952, Acc: 34.38%
    Iteration 380, Loss: 1.0938, Acc: 40.62%
    Iteration 400, Loss: 1.0883, Acc: 40.62%
    Iteration 420, Loss: 1.1115, Acc: 34.38%
Epoch 4 complete. Train Loss: 1.0964, Val Loss: 1.0973, Val Acc: 33.90%, Test Loss: 1.0977, Test Acc: 34.61%
Epoch time: 60.83s

>>> Epoch 5/40
    Iteration 20, Loss: 1.0985, Acc: 34.38%
    Iteration 40, Loss: 1.1007, Acc: 37.50%
    Iteration 60, Loss: 1.1027, Acc: 21.88%
    Iteration 80, Loss: 1.1019, Acc: 43.75%
    Iteration 100, Loss: 1.1005, Acc: 34.38%
    Iteration 120, Loss: 1.0752, Acc: 46.88%
    Iteration 140, Loss: 1.1007, Acc: 31.25%
    Iteration 160, Loss: 1.0950, Acc: 40.62%
    Iteration 180, Loss: 1.0985, Acc: 46.88%
    Iteration 200, Loss: 1.1006, Acc: 46.88%
    Iteration 220, Loss: 1.0952, Acc: 37.50%
    Iteration 240, Loss: 1.0852, Acc: 43.75%
    Iteration 260, Loss: 1.0984, Acc: 34.38%
    Iteration 280, Loss: 1.1010, Acc: 28.12%
    Iteration 300, Loss: 1.1027, Acc: 18.75%
    Iteration 320, Loss: 1.1016, Acc: 31.25%
    Iteration 340, Loss: 1.0936, Acc: 43.75%
    Iteration 360, Loss: 1.0906, Acc: 46.88%
    Iteration 380, Loss: 1.0964, Acc: 43.75%
    Iteration 400, Loss: 1.0964, Acc: 37.50%
    Iteration 420, Loss: 1.1042, Acc: 34.38%
Epoch 5 complete. Train Loss: 1.0967, Val Loss: 1.0970, Val Acc: 33.51%, Test Loss: 1.0973, Test Acc: 35.88%
Epoch time: 59.33s

>>> Epoch 6/40
    Iteration 20, Loss: 1.1020, Acc: 37.50%
    Iteration 40, Loss: 1.0907, Acc: 56.25%
    Iteration 60, Loss: 1.1087, Acc: 18.75%
    Iteration 80, Loss: 1.1014, Acc: 34.38%
    Iteration 100, Loss: 1.0968, Acc: 34.38%
    Iteration 120, Loss: 1.0836, Acc: 37.50%
    Iteration 140, Loss: 1.1067, Acc: 25.00%
    Iteration 160, Loss: 1.0949, Acc: 37.50%
    Iteration 180, Loss: 1.1012, Acc: 37.50%
    Iteration 200, Loss: 1.1008, Acc: 37.50%
    Iteration 220, Loss: 1.0960, Acc: 40.62%
    Iteration 240, Loss: 1.0829, Acc: 37.50%
    Iteration 260, Loss: 1.0944, Acc: 37.50%
    Iteration 280, Loss: 1.0914, Acc: 40.62%
    Iteration 300, Loss: 1.0880, Acc: 28.12%
    Iteration 320, Loss: 1.0900, Acc: 46.88%
    Iteration 340, Loss: 1.0913, Acc: 40.62%
    Iteration 360, Loss: 1.0884, Acc: 53.12%
    Iteration 380, Loss: 1.1010, Acc: 25.00%
    Iteration 400, Loss: 1.0902, Acc: 46.88%
    Iteration 420, Loss: 1.1013, Acc: 50.00%
Epoch 6 complete. Train Loss: 1.0963, Val Loss: 1.0968, Val Acc: 33.77%, Test Loss: 1.0971, Test Acc: 35.76%
Epoch time: 59.74s

>>> Epoch 7/40
    Iteration 20, Loss: 1.1026, Acc: 34.38%
    Iteration 40, Loss: 1.0929, Acc: 43.75%
    Iteration 60, Loss: 1.1021, Acc: 34.38%
    Iteration 80, Loss: 1.1002, Acc: 40.62%
    Iteration 100, Loss: 1.1074, Acc: 31.25%
    Iteration 120, Loss: 1.0698, Acc: 56.25%
    Iteration 140, Loss: 1.0974, Acc: 25.00%
    Iteration 160, Loss: 1.0990, Acc: 40.62%
    Iteration 180, Loss: 1.1010, Acc: 34.38%
    Iteration 200, Loss: 1.0968, Acc: 46.88%
    Iteration 220, Loss: 1.0938, Acc: 43.75%
    Iteration 240, Loss: 1.0816, Acc: 43.75%
    Iteration 260, Loss: 1.0994, Acc: 28.12%
    Iteration 280, Loss: 1.0973, Acc: 37.50%
    Iteration 300, Loss: 1.0886, Acc: 37.50%
    Iteration 320, Loss: 1.0884, Acc: 50.00%
    Iteration 340, Loss: 1.0996, Acc: 37.50%
    Iteration 360, Loss: 1.0899, Acc: 37.50%
    Iteration 380, Loss: 1.0967, Acc: 34.38%
    Iteration 400, Loss: 1.0978, Acc: 25.00%
    Iteration 420, Loss: 1.0988, Acc: 46.88%
Epoch 7 complete. Train Loss: 1.0960, Val Loss: 1.0968, Val Acc: 33.71%, Test Loss: 1.0971, Test Acc: 36.05%
Epoch time: 59.12s

>>> Epoch 8/40
    Iteration 20, Loss: 1.1048, Acc: 21.88%
    Iteration 40, Loss: 1.1022, Acc: 40.62%
    Iteration 60, Loss: 1.1039, Acc: 25.00%
    Iteration 80, Loss: 1.0965, Acc: 40.62%
    Iteration 100, Loss: 1.1176, Acc: 31.25%
    Iteration 120, Loss: 1.0817, Acc: 31.25%
    Iteration 140, Loss: 1.0967, Acc: 37.50%
    Iteration 160, Loss: 1.0955, Acc: 40.62%
    Iteration 180, Loss: 1.0988, Acc: 31.25%
    Iteration 200, Loss: 1.0931, Acc: 43.75%
    Iteration 220, Loss: 1.0930, Acc: 40.62%
    Iteration 240, Loss: 1.0761, Acc: 40.62%
    Iteration 260, Loss: 1.0874, Acc: 50.00%
    Iteration 280, Loss: 1.0975, Acc: 28.12%
    Iteration 300, Loss: 1.0899, Acc: 43.75%
    Iteration 320, Loss: 1.0917, Acc: 43.75%
    Iteration 340, Loss: 1.0919, Acc: 46.88%
    Iteration 360, Loss: 1.0945, Acc: 43.75%
    Iteration 380, Loss: 1.0915, Acc: 34.38%
    Iteration 400, Loss: 1.0899, Acc: 46.88%
    Iteration 420, Loss: 1.0984, Acc: 40.62%
Epoch 8 complete. Train Loss: 1.0961, Val Loss: 1.0968, Val Acc: 33.71%, Test Loss: 1.0971, Test Acc: 36.11%
Epoch time: 59.81s

>>> Epoch 9/40
    Iteration 20, Loss: 1.1087, Acc: 18.75%
    Iteration 40, Loss: 1.1029, Acc: 37.50%
    Iteration 60, Loss: 1.1070, Acc: 34.38%
    Iteration 80, Loss: 1.0993, Acc: 34.38%
    Iteration 100, Loss: 1.1035, Acc: 31.25%
    Iteration 120, Loss: 1.0865, Acc: 40.62%
    Iteration 140, Loss: 1.1007, Acc: 25.00%
    Iteration 160, Loss: 1.1002, Acc: 25.00%
    Iteration 180, Loss: 1.0985, Acc: 43.75%
    Iteration 200, Loss: 1.0940, Acc: 46.88%
    Iteration 220, Loss: 1.1034, Acc: 21.88%
    Iteration 240, Loss: 1.0852, Acc: 37.50%
    Iteration 260, Loss: 1.0907, Acc: 46.88%
    Iteration 280, Loss: 1.0969, Acc: 40.62%
    Iteration 300, Loss: 1.0994, Acc: 28.12%
    Iteration 320, Loss: 1.0948, Acc: 50.00%
    Iteration 340, Loss: 1.0959, Acc: 50.00%
    Iteration 360, Loss: 1.1028, Acc: 28.12%
    Iteration 380, Loss: 1.1038, Acc: 37.50%
    Iteration 400, Loss: 1.0885, Acc: 40.62%
    Iteration 420, Loss: 1.1067, Acc: 37.50%
Epoch 9 complete. Train Loss: 1.0964, Val Loss: 1.0968, Val Acc: 33.71%, Test Loss: 1.0971, Test Acc: 36.11%
Epoch time: 59.49s

>>> Epoch 10/40
    Iteration 20, Loss: 1.0999, Acc: 31.25%
    Iteration 40, Loss: 1.0969, Acc: 40.62%
    Iteration 60, Loss: 1.1121, Acc: 12.50%
    Iteration 80, Loss: 1.1006, Acc: 34.38%
    Iteration 100, Loss: 1.1109, Acc: 25.00%
    Iteration 120, Loss: 1.0945, Acc: 25.00%
    Iteration 140, Loss: 1.0852, Acc: 59.38%
    Iteration 160, Loss: 1.0927, Acc: 50.00%
    Iteration 180, Loss: 1.0972, Acc: 40.62%
    Iteration 200, Loss: 1.0947, Acc: 43.75%
    Iteration 220, Loss: 1.0973, Acc: 34.38%
    Iteration 240, Loss: 1.0843, Acc: 43.75%
    Iteration 260, Loss: 1.0890, Acc: 37.50%
    Iteration 280, Loss: 1.0972, Acc: 37.50%
    Iteration 300, Loss: 1.0918, Acc: 37.50%
    Iteration 320, Loss: 1.0979, Acc: 40.62%
    Iteration 340, Loss: 1.0890, Acc: 53.12%
    Iteration 360, Loss: 1.0913, Acc: 46.88%
    Iteration 380, Loss: 1.0885, Acc: 40.62%
    Iteration 400, Loss: 1.1019, Acc: 34.38%
    Iteration 420, Loss: 1.0961, Acc: 34.38%
Epoch 10 complete. Train Loss: 1.0965, Val Loss: 1.0968, Val Acc: 33.77%, Test Loss: 1.0971, Test Acc: 36.11%
Epoch time: 58.36s

>>> Epoch 11/40
    Iteration 20, Loss: 1.0937, Acc: 37.50%
    Iteration 40, Loss: 1.0948, Acc: 43.75%
    Iteration 60, Loss: 1.1019, Acc: 25.00%
    Iteration 80, Loss: 1.0979, Acc: 43.75%
    Iteration 100, Loss: 1.1020, Acc: 43.75%
    Iteration 120, Loss: 1.0854, Acc: 43.75%
    Iteration 140, Loss: 1.1013, Acc: 37.50%
    Iteration 160, Loss: 1.0925, Acc: 43.75%
    Iteration 180, Loss: 1.0964, Acc: 53.12%
    Iteration 200, Loss: 1.0898, Acc: 40.62%
    Iteration 220, Loss: 1.1023, Acc: 25.00%
    Iteration 240, Loss: 1.0883, Acc: 50.00%
    Iteration 260, Loss: 1.0956, Acc: 40.62%
    Iteration 280, Loss: 1.0966, Acc: 28.12%
    Iteration 300, Loss: 1.0943, Acc: 50.00%
    Iteration 320, Loss: 1.0938, Acc: 56.25%
    Iteration 340, Loss: 1.0941, Acc: 46.88%
    Iteration 360, Loss: 1.0997, Acc: 34.38%
    Iteration 380, Loss: 1.0913, Acc: 40.62%
    Iteration 400, Loss: 1.1010, Acc: 28.12%
    Iteration 420, Loss: 1.0986, Acc: 37.50%
Epoch 11 complete. Train Loss: 1.0962, Val Loss: 1.0968, Val Acc: 33.77%, Test Loss: 1.0971, Test Acc: 36.11%
Epoch time: 58.95s

>>> Epoch 12/40
    Iteration 20, Loss: 1.1033, Acc: 18.75%
    Iteration 40, Loss: 1.0902, Acc: 40.62%
    Iteration 60, Loss: 1.1062, Acc: 25.00%
    Iteration 80, Loss: 1.0990, Acc: 34.38%
    Iteration 100, Loss: 1.1090, Acc: 34.38%
    Iteration 120, Loss: 1.0826, Acc: 34.38%
    Iteration 140, Loss: 1.1004, Acc: 25.00%
    Iteration 160, Loss: 1.0904, Acc: 40.62%
    Iteration 180, Loss: 1.0960, Acc: 43.75%
    Iteration 200, Loss: 1.1013, Acc: 34.38%
    Iteration 220, Loss: 1.0933, Acc: 46.88%
    Iteration 240, Loss: 1.0804, Acc: 43.75%
    Iteration 260, Loss: 1.0995, Acc: 34.38%
    Iteration 280, Loss: 1.0985, Acc: 25.00%
    Iteration 300, Loss: 1.0960, Acc: 37.50%
    Iteration 320, Loss: 1.0924, Acc: 46.88%
    Iteration 340, Loss: 1.0994, Acc: 34.38%
    Iteration 360, Loss: 1.0923, Acc: 31.25%
    Iteration 380, Loss: 1.0892, Acc: 37.50%
    Iteration 400, Loss: 1.0957, Acc: 28.12%
    Iteration 420, Loss: 1.1035, Acc: 31.25%
Epoch 12 complete. Train Loss: 1.0961, Val Loss: 1.0968, Val Acc: 33.77%, Test Loss: 1.0971, Test Acc: 36.11%
Epoch time: 59.09s

>>> Epoch 13/40
    Iteration 20, Loss: 1.1025, Acc: 28.12%
    Iteration 40, Loss: 1.1007, Acc: 37.50%
    Iteration 60, Loss: 1.1059, Acc: 28.12%
    Iteration 80, Loss: 1.1077, Acc: 28.12%
    Iteration 100, Loss: 1.1077, Acc: 28.12%
    Iteration 120, Loss: 1.0914, Acc: 28.12%
    Iteration 140, Loss: 1.0938, Acc: 43.75%
    Iteration 160, Loss: 1.1014, Acc: 25.00%
    Iteration 180, Loss: 1.0998, Acc: 40.62%
    Iteration 200, Loss: 1.0976, Acc: 37.50%
    Iteration 220, Loss: 1.0971, Acc: 40.62%
    Iteration 240, Loss: 1.0880, Acc: 43.75%
    Iteration 260, Loss: 1.1062, Acc: 25.00%
    Iteration 280, Loss: 1.0980, Acc: 28.12%
    Iteration 300, Loss: 1.0956, Acc: 31.25%
    Iteration 320, Loss: 1.0890, Acc: 40.62%
    Iteration 340, Loss: 1.0923, Acc: 34.38%
    Iteration 360, Loss: 1.0880, Acc: 37.50%
    Iteration 380, Loss: 1.1056, Acc: 31.25%
    Iteration 400, Loss: 1.0913, Acc: 43.75%
    Iteration 420, Loss: 1.1097, Acc: 34.38%
Epoch 13 complete. Train Loss: 1.0965, Val Loss: 1.0968, Val Acc: 33.77%, Test Loss: 1.0971, Test Acc: 36.11%
Epoch time: 57.79s

>>> Epoch 14/40
    Iteration 20, Loss: 1.1062, Acc: 21.88%
    Iteration 40, Loss: 1.0956, Acc: 46.88%
    Iteration 60, Loss: 1.1017, Acc: 18.75%
    Iteration 80, Loss: 1.0979, Acc: 37.50%
    Iteration 100, Loss: 1.1007, Acc: 34.38%
    Iteration 120, Loss: 1.0805, Acc: 43.75%
    Iteration 140, Loss: 1.1038, Acc: 25.00%
    Iteration 160, Loss: 1.0962, Acc: 34.38%
    Iteration 180, Loss: 1.0970, Acc: 46.88%
    Iteration 200, Loss: 1.0963, Acc: 37.50%
    Iteration 220, Loss: 1.0942, Acc: 34.38%
    Iteration 240, Loss: 1.0860, Acc: 43.75%
    Iteration 260, Loss: 1.0925, Acc: 40.62%
    Iteration 280, Loss: 1.1035, Acc: 28.12%
    Iteration 300, Loss: 1.0975, Acc: 34.38%
    Iteration 320, Loss: 1.0923, Acc: 46.88%
    Iteration 340, Loss: 1.0997, Acc: 31.25%
    Iteration 360, Loss: 1.0962, Acc: 37.50%
    Iteration 380, Loss: 1.0943, Acc: 43.75%
    Iteration 400, Loss: 1.0911, Acc: 40.62%
    Iteration 420, Loss: 1.1035, Acc: 50.00%
Epoch 14 complete. Train Loss: 1.0960, Val Loss: 1.0968, Val Acc: 33.77%, Test Loss: 1.0971, Test Acc: 36.11%
Epoch time: 58.49s

>>> Epoch 15/40
    Iteration 20, Loss: 1.1014, Acc: 34.38%
    Iteration 40, Loss: 1.0944, Acc: 46.88%
    Iteration 60, Loss: 1.1002, Acc: 25.00%
    Iteration 80, Loss: 1.0990, Acc: 34.38%
    Iteration 100, Loss: 1.1010, Acc: 40.62%
    Iteration 120, Loss: 1.0756, Acc: 40.62%
    Iteration 140, Loss: 1.0989, Acc: 37.50%
    Iteration 160, Loss: 1.0935, Acc: 28.12%
    Iteration 180, Loss: 1.1073, Acc: 34.38%
    Iteration 200, Loss: 1.0981, Acc: 37.50%
    Iteration 220, Loss: 1.1062, Acc: 15.62%
    Iteration 240, Loss: 1.0908, Acc: 37.50%
    Iteration 260, Loss: 1.0989, Acc: 40.62%
    Iteration 280, Loss: 1.0945, Acc: 37.50%
    Iteration 300, Loss: 1.0984, Acc: 40.62%
    Iteration 320, Loss: 1.0975, Acc: 50.00%
    Iteration 340, Loss: 1.0902, Acc: 43.75%
    Iteration 360, Loss: 1.0974, Acc: 37.50%
    Iteration 380, Loss: 1.0910, Acc: 37.50%
    Iteration 400, Loss: 1.0897, Acc: 37.50%
    Iteration 420, Loss: 1.1038, Acc: 34.38%
Epoch 15 complete. Train Loss: 1.0964, Val Loss: 1.0968, Val Acc: 33.84%, Test Loss: 1.0971, Test Acc: 36.11%
Epoch time: 58.91s

>>> Epoch 16/40
    Iteration 20, Loss: 1.0949, Acc: 40.62%
    Iteration 40, Loss: 1.0904, Acc: 43.75%
    Iteration 60, Loss: 1.1067, Acc: 21.88%
    Iteration 80, Loss: 1.1022, Acc: 43.75%
    Iteration 100, Loss: 1.1034, Acc: 40.62%
    Iteration 120, Loss: 1.0839, Acc: 46.88%
    Iteration 140, Loss: 1.0934, Acc: 34.38%
    Iteration 160, Loss: 1.0922, Acc: 40.62%
    Iteration 180, Loss: 1.1014, Acc: 28.12%
    Iteration 200, Loss: 1.0958, Acc: 43.75%
    Iteration 220, Loss: 1.0942, Acc: 37.50%
    Iteration 240, Loss: 1.0791, Acc: 40.62%
    Iteration 260, Loss: 1.0931, Acc: 34.38%
    Iteration 280, Loss: 1.1051, Acc: 21.88%
    Iteration 300, Loss: 1.0941, Acc: 37.50%
    Iteration 320, Loss: 1.0918, Acc: 50.00%
    Iteration 340, Loss: 1.0988, Acc: 37.50%
    Iteration 360, Loss: 1.0867, Acc: 43.75%
    Iteration 380, Loss: 1.0950, Acc: 37.50%
    Iteration 400, Loss: 1.0946, Acc: 31.25%
    Iteration 420, Loss: 1.1074, Acc: 31.25%
Epoch 16 complete. Train Loss: 1.0961, Val Loss: 1.0968, Val Acc: 33.84%, Test Loss: 1.0971, Test Acc: 36.11%
Epoch time: 58.92s

>>> Epoch 17/40
    Iteration 20, Loss: 1.0952, Acc: 43.75%
    Iteration 40, Loss: 1.0891, Acc: 34.38%
    Iteration 60, Loss: 1.1036, Acc: 25.00%
    Iteration 80, Loss: 1.1003, Acc: 37.50%
    Iteration 100, Loss: 1.0994, Acc: 40.62%
    Iteration 120, Loss: 1.0657, Acc: 40.62%
    Iteration 140, Loss: 1.1014, Acc: 40.62%
    Iteration 160, Loss: 1.0933, Acc: 37.50%
    Iteration 180, Loss: 1.1008, Acc: 31.25%
    Iteration 200, Loss: 1.0990, Acc: 37.50%
    Iteration 220, Loss: 1.1047, Acc: 34.38%
    Iteration 240, Loss: 1.0787, Acc: 40.62%
    Iteration 260, Loss: 1.0987, Acc: 34.38%
    Iteration 280, Loss: 1.0947, Acc: 28.12%
    Iteration 300, Loss: 1.0948, Acc: 25.00%
    Iteration 320, Loss: 1.0910, Acc: 37.50%
    Iteration 340, Loss: 1.0902, Acc: 43.75%
    Iteration 360, Loss: 1.0903, Acc: 40.62%
    Iteration 380, Loss: 1.1017, Acc: 28.12%
    Iteration 400, Loss: 1.0939, Acc: 40.62%
    Iteration 420, Loss: 1.1056, Acc: 31.25%
Epoch 17 complete. Train Loss: 1.0960, Val Loss: 1.0968, Val Acc: 33.84%, Test Loss: 1.0971, Test Acc: 36.11%
Epoch time: 57.87s

>>> Epoch 18/40
    Iteration 20, Loss: 1.0989, Acc: 40.62%
    Iteration 40, Loss: 1.0909, Acc: 50.00%
    Iteration 60, Loss: 1.1076, Acc: 25.00%
    Iteration 80, Loss: 1.0998, Acc: 34.38%
    Iteration 100, Loss: 1.1025, Acc: 34.38%
    Iteration 120, Loss: 1.0914, Acc: 43.75%
    Iteration 140, Loss: 1.0926, Acc: 37.50%
    Iteration 160, Loss: 1.0895, Acc: 43.75%
    Iteration 180, Loss: 1.1069, Acc: 40.62%
    Iteration 200, Loss: 1.0913, Acc: 46.88%
    Iteration 220, Loss: 1.0985, Acc: 34.38%
    Iteration 240, Loss: 1.0839, Acc: 37.50%
    Iteration 260, Loss: 1.0960, Acc: 34.38%
    Iteration 280, Loss: 1.0985, Acc: 40.62%
    Iteration 300, Loss: 1.0877, Acc: 40.62%
    Iteration 320, Loss: 1.0971, Acc: 34.38%
    Iteration 340, Loss: 1.0911, Acc: 37.50%
    Iteration 360, Loss: 1.0836, Acc: 50.00%
    Iteration 380, Loss: 1.0934, Acc: 40.62%
    Iteration 400, Loss: 1.0909, Acc: 34.38%
    Iteration 420, Loss: 1.1070, Acc: 31.25%
Epoch 18 complete. Train Loss: 1.0963, Val Loss: 1.0968, Val Acc: 33.84%, Test Loss: 1.0971, Test Acc: 36.11%
Epoch time: 58.40s

>>> Epoch 19/40
    Iteration 20, Loss: 1.0954, Acc: 40.62%
    Iteration 40, Loss: 1.0963, Acc: 37.50%
    Iteration 60, Loss: 1.1067, Acc: 25.00%
    Iteration 80, Loss: 1.1037, Acc: 21.88%
    Iteration 100, Loss: 1.1009, Acc: 34.38%
    Iteration 120, Loss: 1.0767, Acc: 37.50%
    Iteration 140, Loss: 1.1040, Acc: 25.00%
    Iteration 160, Loss: 1.0967, Acc: 40.62%
    Iteration 180, Loss: 1.1004, Acc: 46.88%
    Iteration 200, Loss: 1.0957, Acc: 31.25%
    Iteration 220, Loss: 1.0940, Acc: 37.50%
    Iteration 240, Loss: 1.0897, Acc: 37.50%
    Iteration 260, Loss: 1.0934, Acc: 40.62%
    Iteration 280, Loss: 1.0928, Acc: 43.75%
    Iteration 300, Loss: 1.0852, Acc: 31.25%
    Iteration 320, Loss: 1.0869, Acc: 46.88%
    Iteration 340, Loss: 1.0952, Acc: 46.88%
    Iteration 360, Loss: 1.0963, Acc: 37.50%
    Iteration 380, Loss: 1.0999, Acc: 28.12%
    Iteration 400, Loss: 1.0990, Acc: 34.38%
    Iteration 420, Loss: 1.1119, Acc: 31.25%
Epoch 19 complete. Train Loss: 1.0958, Val Loss: 1.0968, Val Acc: 33.84%, Test Loss: 1.0971, Test Acc: 36.11%
Epoch time: 58.11s

>>> Epoch 20/40
    Iteration 20, Loss: 1.0979, Acc: 31.25%
    Iteration 40, Loss: 1.0984, Acc: 37.50%
    Iteration 60, Loss: 1.1147, Acc: 21.88%
    Iteration 80, Loss: 1.1018, Acc: 37.50%
    Iteration 100, Loss: 1.1113, Acc: 25.00%
    Iteration 120, Loss: 1.0837, Acc: 31.25%
    Iteration 140, Loss: 1.0976, Acc: 28.12%
    Iteration 160, Loss: 1.0962, Acc: 43.75%
    Iteration 180, Loss: 1.0966, Acc: 40.62%
    Iteration 200, Loss: 1.0863, Acc: 50.00%
    Iteration 220, Loss: 1.1041, Acc: 28.12%
    Iteration 240, Loss: 1.1010, Acc: 25.00%
    Iteration 260, Loss: 1.0983, Acc: 43.75%
    Iteration 280, Loss: 1.0971, Acc: 31.25%
    Iteration 300, Loss: 1.0890, Acc: 28.12%
    Iteration 320, Loss: 1.0806, Acc: 50.00%
    Iteration 340, Loss: 1.0914, Acc: 56.25%
    Iteration 360, Loss: 1.0962, Acc: 40.62%
    Iteration 380, Loss: 1.0920, Acc: 37.50%
    Iteration 400, Loss: 1.0968, Acc: 34.38%
    Iteration 420, Loss: 1.1069, Acc: 28.12%
Epoch 20 complete. Train Loss: 1.0963, Val Loss: 1.0968, Val Acc: 33.84%, Test Loss: 1.0971, Test Acc: 36.11%
Epoch time: 58.85s

>>> Epoch 21/40
    Iteration 20, Loss: 1.1045, Acc: 31.25%
    Iteration 40, Loss: 1.0923, Acc: 40.62%
    Iteration 60, Loss: 1.1070, Acc: 28.12%
    Iteration 80, Loss: 1.0992, Acc: 37.50%
    Iteration 100, Loss: 1.1059, Acc: 37.50%
    Iteration 120, Loss: 1.0889, Acc: 34.38%
    Iteration 140, Loss: 1.0985, Acc: 34.38%
    Iteration 160, Loss: 1.1006, Acc: 31.25%
    Iteration 180, Loss: 1.0995, Acc: 43.75%
    Iteration 200, Loss: 1.0964, Acc: 34.38%
    Iteration 220, Loss: 1.1038, Acc: 28.12%
    Iteration 240, Loss: 1.0894, Acc: 43.75%
    Iteration 260, Loss: 1.0855, Acc: 46.88%
    Iteration 280, Loss: 1.0945, Acc: 34.38%
    Iteration 300, Loss: 1.0925, Acc: 34.38%
    Iteration 320, Loss: 1.0872, Acc: 46.88%
    Iteration 340, Loss: 1.0894, Acc: 50.00%
    Iteration 360, Loss: 1.0959, Acc: 25.00%
    Iteration 380, Loss: 1.0915, Acc: 40.62%
    Iteration 400, Loss: 1.0935, Acc: 31.25%
    Iteration 420, Loss: 1.1061, Acc: 28.12%
Epoch 21 complete. Train Loss: 1.0964, Val Loss: 1.0968, Val Acc: 33.84%, Test Loss: 1.0971, Test Acc: 36.11%
Epoch time: 58.65s

>>> Epoch 22/40
    Iteration 20, Loss: 1.0891, Acc: 50.00%
    Iteration 40, Loss: 1.0941, Acc: 46.88%
    Iteration 60, Loss: 1.1018, Acc: 28.12%
    Iteration 80, Loss: 1.0966, Acc: 37.50%
    Iteration 100, Loss: 1.1015, Acc: 34.38%
    Iteration 120, Loss: 1.0809, Acc: 31.25%
    Iteration 140, Loss: 1.0932, Acc: 37.50%
    Iteration 160, Loss: 1.0958, Acc: 43.75%
    Iteration 180, Loss: 1.1126, Acc: 37.50%
    Iteration 200, Loss: 1.0928, Acc: 37.50%
    Iteration 220, Loss: 1.1026, Acc: 37.50%
    Iteration 240, Loss: 1.0865, Acc: 40.62%
    Iteration 260, Loss: 1.0929, Acc: 34.38%
    Iteration 280, Loss: 1.0903, Acc: 37.50%
    Iteration 300, Loss: 1.0896, Acc: 43.75%
    Iteration 320, Loss: 1.0844, Acc: 43.75%
    Iteration 340, Loss: 1.0925, Acc: 50.00%
    Iteration 360, Loss: 1.0940, Acc: 40.62%
    Iteration 380, Loss: 1.0900, Acc: 31.25%
    Iteration 400, Loss: 1.0895, Acc: 37.50%
    Iteration 420, Loss: 1.1040, Acc: 40.62%
Epoch 22 complete. Train Loss: 1.0958, Val Loss: 1.0968, Val Acc: 33.84%, Test Loss: 1.0971, Test Acc: 36.05%
Epoch time: 57.92s

>>> Epoch 23/40
    Iteration 20, Loss: 1.1016, Acc: 34.38%
    Iteration 40, Loss: 1.1003, Acc: 50.00%
    Iteration 60, Loss: 1.1046, Acc: 25.00%
    Iteration 80, Loss: 1.1039, Acc: 37.50%
    Iteration 100, Loss: 1.1044, Acc: 28.12%
    Iteration 120, Loss: 1.0912, Acc: 40.62%
    Iteration 140, Loss: 1.0972, Acc: 37.50%
    Iteration 160, Loss: 1.0961, Acc: 40.62%
    Iteration 180, Loss: 1.1045, Acc: 34.38%
    Iteration 200, Loss: 1.0999, Acc: 46.88%
    Iteration 220, Loss: 1.0932, Acc: 37.50%
    Iteration 240, Loss: 1.0819, Acc: 53.12%
    Iteration 260, Loss: 1.0907, Acc: 37.50%
    Iteration 280, Loss: 1.0874, Acc: 46.88%
    Iteration 300, Loss: 1.0916, Acc: 37.50%
    Iteration 320, Loss: 1.0906, Acc: 43.75%
    Iteration 340, Loss: 1.0916, Acc: 40.62%
    Iteration 360, Loss: 1.0919, Acc: 37.50%
    Iteration 380, Loss: 1.0901, Acc: 40.62%
    Iteration 400, Loss: 1.0850, Acc: 56.25%
    Iteration 420, Loss: 1.1011, Acc: 40.62%
Epoch 23 complete. Train Loss: 1.0961, Val Loss: 1.0968, Val Acc: 33.84%, Test Loss: 1.0971, Test Acc: 36.05%
Epoch time: 59.06s

>>> Epoch 24/40
    Iteration 20, Loss: 1.1071, Acc: 9.38%
    Iteration 40, Loss: 1.0994, Acc: 37.50%
    Iteration 60, Loss: 1.1006, Acc: 25.00%
    Iteration 80, Loss: 1.0945, Acc: 40.62%
    Iteration 100, Loss: 1.1069, Acc: 28.12%
    Iteration 120, Loss: 1.0986, Acc: 31.25%
    Iteration 140, Loss: 1.0935, Acc: 53.12%
    Iteration 160, Loss: 1.0977, Acc: 37.50%
    Iteration 180, Loss: 1.1024, Acc: 37.50%
    Iteration 200, Loss: 1.0902, Acc: 46.88%
    Iteration 220, Loss: 1.0916, Acc: 43.75%
    Iteration 240, Loss: 1.1041, Acc: 37.50%
    Iteration 260, Loss: 1.0943, Acc: 40.62%
    Iteration 280, Loss: 1.0963, Acc: 28.12%
    Iteration 300, Loss: 1.1043, Acc: 28.12%
    Iteration 320, Loss: 1.0967, Acc: 31.25%
    Iteration 340, Loss: 1.0945, Acc: 40.62%
    Iteration 360, Loss: 1.0885, Acc: 40.62%
    Iteration 380, Loss: 1.1002, Acc: 34.38%
    Iteration 400, Loss: 1.0897, Acc: 37.50%
    Iteration 420, Loss: 1.1004, Acc: 46.88%
Epoch 24 complete. Train Loss: 1.0964, Val Loss: 1.0968, Val Acc: 33.84%, Test Loss: 1.0971, Test Acc: 36.05%
Epoch time: 58.97s

>>> Epoch 25/40
    Iteration 20, Loss: 1.1026, Acc: 21.88%
    Iteration 40, Loss: 1.0890, Acc: 56.25%
    Iteration 60, Loss: 1.1053, Acc: 25.00%
    Iteration 80, Loss: 1.0947, Acc: 43.75%
    Iteration 100, Loss: 1.1113, Acc: 34.38%
    Iteration 120, Loss: 1.0775, Acc: 53.12%
    Iteration 140, Loss: 1.0982, Acc: 31.25%
    Iteration 160, Loss: 1.0986, Acc: 34.38%
    Iteration 180, Loss: 1.1005, Acc: 37.50%
    Iteration 200, Loss: 1.0979, Acc: 37.50%
    Iteration 220, Loss: 1.1033, Acc: 40.62%
    Iteration 240, Loss: 1.0849, Acc: 50.00%
    Iteration 260, Loss: 1.0953, Acc: 46.88%
    Iteration 280, Loss: 1.0958, Acc: 34.38%
    Iteration 300, Loss: 1.1000, Acc: 37.50%
    Iteration 320, Loss: 1.0932, Acc: 43.75%
    Iteration 340, Loss: 1.0953, Acc: 37.50%
    Iteration 360, Loss: 1.1032, Acc: 34.38%
    Iteration 380, Loss: 1.0914, Acc: 43.75%
    Iteration 400, Loss: 1.0973, Acc: 31.25%
    Iteration 420, Loss: 1.1024, Acc: 37.50%
Epoch 25 complete. Train Loss: 1.0965, Val Loss: 1.0968, Val Acc: 33.84%, Test Loss: 1.0971, Test Acc: 36.05%
Epoch time: 59.07s

>>> Epoch 26/40
    Iteration 20, Loss: 1.1034, Acc: 31.25%
    Iteration 40, Loss: 1.0977, Acc: 40.62%
    Iteration 60, Loss: 1.1085, Acc: 18.75%
    Iteration 80, Loss: 1.0966, Acc: 31.25%
    Iteration 100, Loss: 1.1055, Acc: 25.00%
    Iteration 120, Loss: 1.0581, Acc: 43.75%
    Iteration 140, Loss: 1.1025, Acc: 37.50%
    Iteration 160, Loss: 1.0937, Acc: 31.25%
    Iteration 180, Loss: 1.1016, Acc: 34.38%
    Iteration 200, Loss: 1.0966, Acc: 31.25%
    Iteration 220, Loss: 1.0999, Acc: 21.88%
    Iteration 240, Loss: 1.0916, Acc: 37.50%
    Iteration 260, Loss: 1.0963, Acc: 37.50%
    Iteration 280, Loss: 1.1003, Acc: 25.00%
    Iteration 300, Loss: 1.0838, Acc: 40.62%
    Iteration 320, Loss: 1.0969, Acc: 31.25%
    Iteration 340, Loss: 1.0908, Acc: 46.88%
    Iteration 360, Loss: 1.0954, Acc: 34.38%
    Iteration 380, Loss: 1.1011, Acc: 34.38%
    Iteration 400, Loss: 1.0965, Acc: 31.25%
    Iteration 420, Loss: 1.1071, Acc: 31.25%
Epoch 26 complete. Train Loss: 1.0963, Val Loss: 1.0968, Val Acc: 33.84%, Test Loss: 1.0971, Test Acc: 36.05%
Epoch time: 57.99s

>>> Epoch 27/40
    Iteration 20, Loss: 1.1004, Acc: 34.38%
    Iteration 40, Loss: 1.0860, Acc: 56.25%
    Iteration 60, Loss: 1.1108, Acc: 21.88%
    Iteration 80, Loss: 1.0980, Acc: 34.38%
    Iteration 100, Loss: 1.1066, Acc: 28.12%
    Iteration 120, Loss: 1.0834, Acc: 43.75%
    Iteration 140, Loss: 1.1094, Acc: 21.88%
    Iteration 160, Loss: 1.0925, Acc: 46.88%
    Iteration 180, Loss: 1.0935, Acc: 46.88%
    Iteration 200, Loss: 1.0837, Acc: 53.12%
    Iteration 220, Loss: 1.0928, Acc: 43.75%
    Iteration 240, Loss: 1.0857, Acc: 28.12%
    Iteration 260, Loss: 1.0930, Acc: 46.88%
    Iteration 280, Loss: 1.1001, Acc: 28.12%
    Iteration 300, Loss: 1.0935, Acc: 34.38%
    Iteration 320, Loss: 1.0983, Acc: 37.50%
    Iteration 340, Loss: 1.0872, Acc: 37.50%
    Iteration 360, Loss: 1.0974, Acc: 31.25%
    Iteration 380, Loss: 1.0971, Acc: 40.62%
    Iteration 400, Loss: 1.0916, Acc: 43.75%
    Iteration 420, Loss: 1.1034, Acc: 31.25%
Epoch 27 complete. Train Loss: 1.0965, Val Loss: 1.0968, Val Acc: 33.84%, Test Loss: 1.0971, Test Acc: 36.05%
Epoch time: 58.63s

>>> Epoch 28/40
    Iteration 20, Loss: 1.1023, Acc: 25.00%
    Iteration 40, Loss: 1.0958, Acc: 43.75%
    Iteration 60, Loss: 1.1061, Acc: 31.25%
    Iteration 80, Loss: 1.0994, Acc: 40.62%
    Iteration 100, Loss: 1.1029, Acc: 28.12%
    Iteration 120, Loss: 1.0821, Acc: 37.50%
    Iteration 140, Loss: 1.1020, Acc: 28.12%
    Iteration 160, Loss: 1.0955, Acc: 50.00%
    Iteration 180, Loss: 1.0935, Acc: 34.38%
    Iteration 200, Loss: 1.0916, Acc: 37.50%
    Iteration 220, Loss: 1.0999, Acc: 31.25%
    Iteration 240, Loss: 1.0829, Acc: 46.88%
    Iteration 260, Loss: 1.0960, Acc: 40.62%
    Iteration 280, Loss: 1.0980, Acc: 40.62%
    Iteration 300, Loss: 1.0938, Acc: 28.12%
    Iteration 320, Loss: 1.0898, Acc: 50.00%
    Iteration 340, Loss: 1.0923, Acc: 37.50%
    Iteration 360, Loss: 1.0957, Acc: 46.88%
    Iteration 380, Loss: 1.0919, Acc: 40.62%
    Iteration 400, Loss: 1.0903, Acc: 40.62%
    Iteration 420, Loss: 1.1038, Acc: 46.88%
Epoch 28 complete. Train Loss: 1.0962, Val Loss: 1.0968, Val Acc: 33.84%, Test Loss: 1.0970, Test Acc: 36.05%
Epoch time: 59.02s

>>> Epoch 29/40
    Iteration 20, Loss: 1.0950, Acc: 34.38%
    Iteration 40, Loss: 1.0977, Acc: 34.38%
    Iteration 60, Loss: 1.1010, Acc: 28.12%
    Iteration 80, Loss: 1.0921, Acc: 37.50%
    Iteration 100, Loss: 1.1152, Acc: 21.88%
    Iteration 120, Loss: 1.0851, Acc: 56.25%
    Iteration 140, Loss: 1.0970, Acc: 34.38%
    Iteration 160, Loss: 1.1004, Acc: 31.25%
    Iteration 180, Loss: 1.1009, Acc: 31.25%
    Iteration 200, Loss: 1.0936, Acc: 46.88%
    Iteration 220, Loss: 1.1005, Acc: 31.25%
    Iteration 240, Loss: 1.0874, Acc: 40.62%
    Iteration 260, Loss: 1.0961, Acc: 40.62%
    Iteration 280, Loss: 1.0913, Acc: 34.38%
    Iteration 300, Loss: 1.0929, Acc: 43.75%
    Iteration 320, Loss: 1.0969, Acc: 37.50%
    Iteration 340, Loss: 1.0955, Acc: 43.75%
    Iteration 360, Loss: 1.0844, Acc: 53.12%
    Iteration 380, Loss: 1.0944, Acc: 28.12%
    Iteration 400, Loss: 1.0967, Acc: 40.62%
    Iteration 420, Loss: 1.1014, Acc: 31.25%
Epoch 29 complete. Train Loss: 1.0958, Val Loss: 1.0968, Val Acc: 33.84%, Test Loss: 1.0970, Test Acc: 36.05%
Epoch time: 58.97s

>>> Epoch 30/40
    Iteration 20, Loss: 1.1044, Acc: 34.38%
    Iteration 40, Loss: 1.1039, Acc: 43.75%
    Iteration 60, Loss: 1.1076, Acc: 34.38%
    Iteration 80, Loss: 1.0993, Acc: 34.38%
    Iteration 100, Loss: 1.1003, Acc: 34.38%
    Iteration 120, Loss: 1.0813, Acc: 46.88%
    Iteration 140, Loss: 1.0960, Acc: 31.25%
    Iteration 160, Loss: 1.0963, Acc: 25.00%
    Iteration 180, Loss: 1.1039, Acc: 31.25%
    Iteration 200, Loss: 1.0970, Acc: 31.25%
    Iteration 220, Loss: 1.0938, Acc: 37.50%
    Iteration 240, Loss: 1.0884, Acc: 43.75%
    Iteration 260, Loss: 1.1024, Acc: 40.62%
    Iteration 280, Loss: 1.0858, Acc: 43.75%
    Iteration 300, Loss: 1.1012, Acc: 21.88%
    Iteration 320, Loss: 1.0917, Acc: 46.88%
    Iteration 340, Loss: 1.0893, Acc: 43.75%
    Iteration 360, Loss: 1.0951, Acc: 46.88%
    Iteration 380, Loss: 1.0926, Acc: 37.50%
    Iteration 400, Loss: 1.0971, Acc: 31.25%
    Iteration 420, Loss: 1.1014, Acc: 37.50%
Epoch 30 complete. Train Loss: 1.0961, Val Loss: 1.0968, Val Acc: 33.84%, Test Loss: 1.0970, Test Acc: 36.05%
Epoch time: 59.04s

>>> Epoch 31/40
    Iteration 20, Loss: 1.1017, Acc: 18.75%
    Iteration 40, Loss: 1.0965, Acc: 40.62%
    Iteration 60, Loss: 1.1100, Acc: 18.75%
    Iteration 80, Loss: 1.0990, Acc: 37.50%
    Iteration 100, Loss: 1.1026, Acc: 37.50%
    Iteration 120, Loss: 1.0908, Acc: 34.38%
    Iteration 140, Loss: 1.0984, Acc: 37.50%
    Iteration 160, Loss: 1.0975, Acc: 40.62%
    Iteration 180, Loss: 1.0972, Acc: 37.50%
    Iteration 200, Loss: 1.0937, Acc: 53.12%
    Iteration 220, Loss: 1.1018, Acc: 34.38%
    Iteration 240, Loss: 1.0873, Acc: 43.75%
    Iteration 260, Loss: 1.0915, Acc: 31.25%
    Iteration 280, Loss: 1.1008, Acc: 34.38%
    Iteration 300, Loss: 1.0841, Acc: 50.00%
    Iteration 320, Loss: 1.0922, Acc: 53.12%
    Iteration 340, Loss: 1.0838, Acc: 43.75%
    Iteration 360, Loss: 1.0954, Acc: 43.75%
    Iteration 380, Loss: 1.0938, Acc: 37.50%
    Iteration 400, Loss: 1.0965, Acc: 31.25%
    Iteration 420, Loss: 1.1054, Acc: 34.38%
Epoch 31 complete. Train Loss: 1.0965, Val Loss: 1.0968, Val Acc: 33.84%, Test Loss: 1.0970, Test Acc: 36.05%
Epoch time: 57.30s

>>> Epoch 32/40
    Iteration 20, Loss: 1.0941, Acc: 25.00%
    Iteration 40, Loss: 1.0910, Acc: 43.75%
    Iteration 60, Loss: 1.1041, Acc: 28.12%
    Iteration 80, Loss: 1.0976, Acc: 40.62%
    Iteration 100, Loss: 1.1070, Acc: 34.38%
    Iteration 120, Loss: 1.0760, Acc: 46.88%
    Iteration 140, Loss: 1.0986, Acc: 25.00%
    Iteration 160, Loss: 1.0998, Acc: 34.38%
    Iteration 180, Loss: 1.1069, Acc: 31.25%
    Iteration 200, Loss: 1.0952, Acc: 37.50%
    Iteration 220, Loss: 1.1009, Acc: 37.50%
    Iteration 240, Loss: 1.0777, Acc: 53.12%
    Iteration 260, Loss: 1.0910, Acc: 46.88%
    Iteration 280, Loss: 1.0935, Acc: 28.12%
    Iteration 300, Loss: 1.0980, Acc: 25.00%
    Iteration 320, Loss: 1.0782, Acc: 56.25%
    Iteration 340, Loss: 1.0946, Acc: 46.88%
    Iteration 360, Loss: 1.0847, Acc: 46.88%
    Iteration 380, Loss: 1.0888, Acc: 50.00%
    Iteration 400, Loss: 1.0899, Acc: 40.62%
    Iteration 420, Loss: 1.0945, Acc: 40.62%
Epoch 32 complete. Train Loss: 1.0963, Val Loss: 1.0968, Val Acc: 33.84%, Test Loss: 1.0970, Test Acc: 36.05%
Epoch time: 59.00s

>>> Epoch 33/40
    Iteration 20, Loss: 1.0946, Acc: 43.75%
    Iteration 40, Loss: 1.0934, Acc: 40.62%
    Iteration 60, Loss: 1.1060, Acc: 34.38%
    Iteration 80, Loss: 1.0981, Acc: 34.38%
    Iteration 100, Loss: 1.1054, Acc: 40.62%
    Iteration 120, Loss: 1.0706, Acc: 40.62%
    Iteration 140, Loss: 1.1060, Acc: 18.75%
    Iteration 160, Loss: 1.1026, Acc: 28.12%
    Iteration 180, Loss: 1.0987, Acc: 50.00%
    Iteration 200, Loss: 1.0920, Acc: 43.75%
    Iteration 220, Loss: 1.1001, Acc: 34.38%
    Iteration 240, Loss: 1.0916, Acc: 37.50%
    Iteration 260, Loss: 1.0909, Acc: 50.00%
    Iteration 280, Loss: 1.0946, Acc: 37.50%
    Iteration 300, Loss: 1.0892, Acc: 37.50%
    Iteration 320, Loss: 1.0891, Acc: 40.62%
    Iteration 340, Loss: 1.0889, Acc: 53.12%
    Iteration 360, Loss: 1.1023, Acc: 37.50%
    Iteration 380, Loss: 1.1045, Acc: 28.12%
    Iteration 400, Loss: 1.0925, Acc: 31.25%
    Iteration 420, Loss: 1.1037, Acc: 31.25%
Epoch 33 complete. Train Loss: 1.0965, Val Loss: 1.0968, Val Acc: 33.84%, Test Loss: 1.0970, Test Acc: 36.05%
Epoch time: 58.99s

>>> Epoch 34/40
    Iteration 20, Loss: 1.0987, Acc: 37.50%
    Iteration 40, Loss: 1.0939, Acc: 37.50%
    Iteration 60, Loss: 1.1037, Acc: 28.12%
    Iteration 80, Loss: 1.0995, Acc: 31.25%
    Iteration 100, Loss: 1.1091, Acc: 37.50%
    Iteration 120, Loss: 1.0891, Acc: 37.50%
    Iteration 140, Loss: 1.0959, Acc: 40.62%
    Iteration 160, Loss: 1.0919, Acc: 40.62%
    Iteration 180, Loss: 1.1101, Acc: 37.50%
    Iteration 200, Loss: 1.0859, Acc: 50.00%
    Iteration 220, Loss: 1.0990, Acc: 31.25%
    Iteration 240, Loss: 1.0909, Acc: 34.38%
    Iteration 260, Loss: 1.0868, Acc: 50.00%
    Iteration 280, Loss: 1.0936, Acc: 25.00%
    Iteration 300, Loss: 1.0946, Acc: 43.75%
    Iteration 320, Loss: 1.0890, Acc: 43.75%
    Iteration 340, Loss: 1.0913, Acc: 46.88%
    Iteration 360, Loss: 1.0910, Acc: 40.62%
    Iteration 380, Loss: 1.0958, Acc: 34.38%
    Iteration 400, Loss: 1.0886, Acc: 46.88%
    Iteration 420, Loss: 1.1050, Acc: 31.25%
Epoch 34 complete. Train Loss: 1.0964, Val Loss: 1.0968, Val Acc: 33.84%, Test Loss: 1.0970, Test Acc: 36.05%
Epoch time: 59.08s

>>> Epoch 35/40
    Iteration 20, Loss: 1.1057, Acc: 21.88%
    Iteration 40, Loss: 1.0807, Acc: 46.88%
    Iteration 60, Loss: 1.1009, Acc: 37.50%
    Iteration 80, Loss: 1.0985, Acc: 40.62%
    Iteration 100, Loss: 1.1108, Acc: 25.00%
    Iteration 120, Loss: 1.0832, Acc: 37.50%
    Iteration 140, Loss: 1.1047, Acc: 28.12%
    Iteration 160, Loss: 1.1004, Acc: 37.50%
    Iteration 180, Loss: 1.1116, Acc: 25.00%
    Iteration 200, Loss: 1.0928, Acc: 37.50%
    Iteration 220, Loss: 1.1003, Acc: 28.12%
    Iteration 240, Loss: 1.0941, Acc: 31.25%
    Iteration 260, Loss: 1.0905, Acc: 46.88%
    Iteration 280, Loss: 1.0975, Acc: 40.62%
    Iteration 300, Loss: 1.1001, Acc: 21.88%
    Iteration 320, Loss: 1.0847, Acc: 53.12%
    Iteration 340, Loss: 1.0926, Acc: 46.88%
    Iteration 360, Loss: 1.0922, Acc: 34.38%
    Iteration 380, Loss: 1.0926, Acc: 43.75%
    Iteration 400, Loss: 1.0974, Acc: 34.38%
    Iteration 420, Loss: 1.1105, Acc: 40.62%
Epoch 35 complete. Train Loss: 1.0961, Val Loss: 1.0968, Val Acc: 33.84%, Test Loss: 1.0970, Test Acc: 36.05%
Epoch time: 60.11s

>>> Epoch 36/40
    Iteration 20, Loss: 1.0961, Acc: 28.12%
    Iteration 40, Loss: 1.0983, Acc: 46.88%
    Iteration 60, Loss: 1.1078, Acc: 31.25%
    Iteration 80, Loss: 1.0933, Acc: 37.50%
    Iteration 100, Loss: 1.1012, Acc: 34.38%
    Iteration 120, Loss: 1.0942, Acc: 37.50%
    Iteration 140, Loss: 1.0999, Acc: 34.38%
    Iteration 160, Loss: 1.0938, Acc: 37.50%
    Iteration 180, Loss: 1.1115, Acc: 34.38%
    Iteration 200, Loss: 1.0852, Acc: 43.75%
    Iteration 220, Loss: 1.0992, Acc: 31.25%
    Iteration 240, Loss: 1.0841, Acc: 50.00%
    Iteration 260, Loss: 1.0953, Acc: 46.88%
    Iteration 280, Loss: 1.0975, Acc: 37.50%
    Iteration 300, Loss: 1.0901, Acc: 37.50%
    Iteration 320, Loss: 1.0864, Acc: 53.12%
    Iteration 340, Loss: 1.0796, Acc: 53.12%
    Iteration 360, Loss: 1.0897, Acc: 40.62%
    Iteration 380, Loss: 1.0942, Acc: 37.50%
    Iteration 400, Loss: 1.0932, Acc: 31.25%
    Iteration 420, Loss: 1.1126, Acc: 28.12%
Epoch 36 complete. Train Loss: 1.0966, Val Loss: 1.0967, Val Acc: 33.84%, Test Loss: 1.0970, Test Acc: 36.05%
Epoch time: 57.63s

>>> Epoch 37/40
    Iteration 20, Loss: 1.0940, Acc: 34.38%
    Iteration 40, Loss: 1.0963, Acc: 50.00%
    Iteration 60, Loss: 1.1086, Acc: 21.88%
    Iteration 80, Loss: 1.0994, Acc: 37.50%
    Iteration 100, Loss: 1.1040, Acc: 43.75%
    Iteration 120, Loss: 1.0822, Acc: 56.25%
    Iteration 140, Loss: 1.1014, Acc: 31.25%
    Iteration 160, Loss: 1.0929, Acc: 50.00%
    Iteration 180, Loss: 1.0965, Acc: 43.75%
    Iteration 200, Loss: 1.0859, Acc: 50.00%
    Iteration 220, Loss: 1.1020, Acc: 31.25%
    Iteration 240, Loss: 1.0916, Acc: 40.62%
    Iteration 260, Loss: 1.0902, Acc: 50.00%
    Iteration 280, Loss: 1.0913, Acc: 34.38%
    Iteration 300, Loss: 1.1071, Acc: 18.75%
    Iteration 320, Loss: 1.0840, Acc: 46.88%
    Iteration 340, Loss: 1.1000, Acc: 43.75%
    Iteration 360, Loss: 1.0985, Acc: 34.38%
    Iteration 380, Loss: 1.0898, Acc: 43.75%
    Iteration 400, Loss: 1.0900, Acc: 43.75%
    Iteration 420, Loss: 1.0999, Acc: 34.38%
Epoch 37 complete. Train Loss: 1.0960, Val Loss: 1.0967, Val Acc: 33.84%, Test Loss: 1.0970, Test Acc: 36.05%
Epoch time: 58.90s

>>> Epoch 38/40
    Iteration 20, Loss: 1.1002, Acc: 40.62%
    Iteration 40, Loss: 1.0935, Acc: 43.75%
    Iteration 60, Loss: 1.1051, Acc: 25.00%
    Iteration 80, Loss: 1.0974, Acc: 40.62%
    Iteration 100, Loss: 1.1082, Acc: 21.88%
    Iteration 120, Loss: 1.0916, Acc: 34.38%
    Iteration 140, Loss: 1.1058, Acc: 12.50%
    Iteration 160, Loss: 1.0998, Acc: 40.62%
    Iteration 180, Loss: 1.0917, Acc: 37.50%
    Iteration 200, Loss: 1.0927, Acc: 34.38%
    Iteration 220, Loss: 1.0966, Acc: 31.25%
    Iteration 240, Loss: 1.0901, Acc: 40.62%
    Iteration 260, Loss: 1.1008, Acc: 37.50%
    Iteration 280, Loss: 1.0960, Acc: 25.00%
    Iteration 300, Loss: 1.0873, Acc: 46.88%
    Iteration 320, Loss: 1.0908, Acc: 50.00%
    Iteration 340, Loss: 1.0891, Acc: 50.00%
    Iteration 360, Loss: 1.0868, Acc: 43.75%
    Iteration 380, Loss: 1.0929, Acc: 37.50%
    Iteration 400, Loss: 1.0903, Acc: 37.50%
    Iteration 420, Loss: 1.0960, Acc: 53.12%
Epoch 38 complete. Train Loss: 1.0963, Val Loss: 1.0967, Val Acc: 33.84%, Test Loss: 1.0970, Test Acc: 36.05%
Epoch time: 59.12s

>>> Epoch 39/40
    Iteration 20, Loss: 1.1052, Acc: 34.38%
    Iteration 40, Loss: 1.0962, Acc: 34.38%
    Iteration 60, Loss: 1.1068, Acc: 25.00%
    Iteration 80, Loss: 1.0937, Acc: 40.62%
    Iteration 100, Loss: 1.1049, Acc: 46.88%
    Iteration 120, Loss: 1.0979, Acc: 37.50%
    Iteration 140, Loss: 1.0983, Acc: 34.38%
    Iteration 160, Loss: 1.1030, Acc: 31.25%
    Iteration 180, Loss: 1.0983, Acc: 37.50%
    Iteration 200, Loss: 1.0935, Acc: 46.88%
    Iteration 220, Loss: 1.1029, Acc: 31.25%
    Iteration 240, Loss: 1.0969, Acc: 37.50%
    Iteration 260, Loss: 1.0957, Acc: 50.00%
    Iteration 280, Loss: 1.0932, Acc: 37.50%
    Iteration 300, Loss: 1.0904, Acc: 25.00%
    Iteration 320, Loss: 1.0950, Acc: 43.75%
    Iteration 340, Loss: 1.0920, Acc: 34.38%
    Iteration 360, Loss: 1.0954, Acc: 37.50%
    Iteration 380, Loss: 1.0987, Acc: 28.12%
    Iteration 400, Loss: 1.0996, Acc: 28.12%
    Iteration 420, Loss: 1.0923, Acc: 50.00%
Epoch 39 complete. Train Loss: 1.0960, Val Loss: 1.0967, Val Acc: 33.84%, Test Loss: 1.0970, Test Acc: 36.05%
Epoch time: 58.97s

>>> Epoch 40/40
    Iteration 20, Loss: 1.0986, Acc: 31.25%
    Iteration 40, Loss: 1.0937, Acc: 43.75%
    Iteration 60, Loss: 1.0960, Acc: 37.50%
    Iteration 80, Loss: 1.0975, Acc: 37.50%
    Iteration 100, Loss: 1.1001, Acc: 59.38%
    Iteration 120, Loss: 1.0933, Acc: 34.38%
    Iteration 140, Loss: 1.1031, Acc: 34.38%
    Iteration 160, Loss: 1.0975, Acc: 28.12%
    Iteration 180, Loss: 1.1074, Acc: 28.12%
    Iteration 200, Loss: 1.0947, Acc: 37.50%
    Iteration 220, Loss: 1.0990, Acc: 37.50%
    Iteration 240, Loss: 1.0909, Acc: 40.62%
    Iteration 260, Loss: 1.0914, Acc: 43.75%
    Iteration 280, Loss: 1.0960, Acc: 40.62%
    Iteration 300, Loss: 1.0895, Acc: 21.88%
    Iteration 320, Loss: 1.0921, Acc: 56.25%
    Iteration 340, Loss: 1.0923, Acc: 43.75%
    Iteration 360, Loss: 1.0944, Acc: 40.62%
    Iteration 380, Loss: 1.0920, Acc: 43.75%
    Iteration 400, Loss: 1.0934, Acc: 34.38%
    Iteration 420, Loss: 1.1017, Acc: 43.75%
Epoch 40 complete. Train Loss: 1.0962, Val Loss: 1.0967, Val Acc: 33.84%, Test Loss: 1.0970, Test Acc: 36.05%
Epoch time: 57.90s
Train/val/test loss curve saved to /tmp/run_project_logs/train_val_test_loss_curve.png
Confusion matrix saved to /tmp/run_project_logs/confusion_matrix.png

Done. TensorBoard logs + confusion matrix + trainval curves all saved.
