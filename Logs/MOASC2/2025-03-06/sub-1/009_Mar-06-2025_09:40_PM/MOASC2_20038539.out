SLURM Job ID: 20038539
directory /home/rgg2706/Multimodal-Sentiment-Analysis/OpinionMining/Datasets exists
directory /home/rgg2706/Multimodal-Sentiment-Analysis/Models/MOASC2/SaveFiles exists

> Logs + images will be saved in: /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/MOASC2/2025-03-06/sub-1/009_Mar-06-2025_09:40_PM
Error loading image /home/rgg2706/Multimodal-Sentiment-Analysis/Datasets/MVSA_Multiple2/images/3149.jpg: cannot identify image file '/home/rgg2706/Multimodal-Sentiment-Analysis/Datasets/MVSA_Multiple2/images/3149.jpg'
  [*] Using fallback image: /home/rgg2706/Multimodal-Sentiment-Analysis/Datasets/0default.jpg
Error loading image /home/rgg2706/Multimodal-Sentiment-Analysis/Datasets/MVSA_Multiple2/images/12244.jpg: image file is truncated (4 bytes not processed)
  [*] Using fallback image: /home/rgg2706/Multimodal-Sentiment-Analysis/Datasets/0default.jpg
Error loading image /home/rgg2706/Multimodal-Sentiment-Analysis/Datasets/MVSA_Multiple2/images/1337.jpg: cannot identify image file '/home/rgg2706/Multimodal-Sentiment-Analysis/Datasets/MVSA_Multiple2/images/1337.jpg'
  [*] Using fallback image: /home/rgg2706/Multimodal-Sentiment-Analysis/Datasets/0default.jpg

=== DATASET DEBUG INFO ===
Dataset name: MVSA_Multiple2
Train set size: 14274
Val set size: 1587
Test set size: 1763
Max text length: 23

[Sample of training data]
  Index 0 ID => text: 'knocked doors with the venerable  team trudeau lpc candidate kylejpeterson this aft in my hometown  aurora! elxn'
              label: 2
  Index 1 ID => text: 'canvassing for  elect kelly yeg yegfed elxn'
              label: 1
  Index 2 ID => text: 'i think it is time for change   ana  commit to  vote  generation trudeau  sfu lpc elxn http annoyedorhesitantt.cohvo i ud x ib'
              label: 2
========================


>>> Epoch 1/40
    Iteration 20, Loss: 1.0965, Acc: 37.50%
    Iteration 40, Loss: 1.1023, Acc: 37.50%
    Iteration 60, Loss: 1.1037, Acc: 37.50%
    Iteration 80, Loss: 1.1025, Acc: 28.12%
    Iteration 100, Loss: 1.1009, Acc: 37.50%
    Iteration 120, Loss: 1.0994, Acc: 81.25%
    Iteration 140, Loss: 1.1005, Acc: 37.50%
    Iteration 160, Loss: 1.1022, Acc: 40.62%
    Iteration 180, Loss: 1.1014, Acc: 56.25%
    Iteration 200, Loss: 1.0996, Acc: 37.50%
    Iteration 220, Loss: 1.1022, Acc: 25.00%
    Iteration 240, Loss: 1.0935, Acc: 40.62%
    Iteration 260, Loss: 1.1044, Acc: 21.88%
    Iteration 280, Loss: 1.1082, Acc: 18.75%
    Iteration 300, Loss: 1.0985, Acc: 37.50%
    Iteration 320, Loss: 1.0930, Acc: 37.50%
    Iteration 340, Loss: 1.1010, Acc: 31.25%
    Iteration 360, Loss: 1.0937, Acc: 46.88%
    Iteration 380, Loss: 1.0966, Acc: 53.12%
    Iteration 400, Loss: 1.0960, Acc: 28.12%
    Iteration 420, Loss: 1.0976, Acc: 53.12%
Epoch 1 complete. Train Loss: 1.0994, Val Loss: 1.0992, Val Acc: 30.80%, Test Loss: 1.0993, Test Acc: 27.51%
  [*] New best val_acc = 0.3080
  [*] New best test_acc = 0.2751, saving model...
Epoch time: 58.73s

>>> Epoch 2/40
    Iteration 20, Loss: 1.0999, Acc: 31.25%
    Iteration 40, Loss: 1.0977, Acc: 50.00%
    Iteration 60, Loss: 1.1052, Acc: 18.75%
    Iteration 80, Loss: 1.0868, Acc: 56.25%
    Iteration 100, Loss: 1.0930, Acc: 34.38%
    Iteration 120, Loss: 1.1027, Acc: 71.88%
    Iteration 140, Loss: 1.0982, Acc: 40.62%
    Iteration 160, Loss: 1.1022, Acc: 28.12%
    Iteration 180, Loss: 1.1043, Acc: 40.62%
    Iteration 200, Loss: 1.0979, Acc: 40.62%
    Iteration 220, Loss: 1.1052, Acc: 15.62%
    Iteration 240, Loss: 1.0960, Acc: 37.50%
    Iteration 260, Loss: 1.0986, Acc: 18.75%
    Iteration 280, Loss: 1.1040, Acc: 31.25%
    Iteration 300, Loss: 1.0968, Acc: 21.88%
    Iteration 320, Loss: 1.0973, Acc: 50.00%
    Iteration 340, Loss: 1.1022, Acc: 34.38%
    Iteration 360, Loss: 1.1066, Acc: 21.88%
    Iteration 380, Loss: 1.0949, Acc: 40.62%
    Iteration 400, Loss: 1.1011, Acc: 28.12%
    Iteration 420, Loss: 1.1006, Acc: 31.25%
Epoch 2 complete. Train Loss: 1.0981, Val Loss: 1.1006, Val Acc: 26.76%, Test Loss: 1.1006, Test Acc: 26.34%
Epoch time: 56.36s

>>> Epoch 3/40
    Iteration 20, Loss: 1.1037, Acc: 28.12%
    Iteration 40, Loss: 1.1027, Acc: 34.38%
    Iteration 60, Loss: 1.0992, Acc: 37.50%
    Iteration 80, Loss: 1.1007, Acc: 34.38%
    Iteration 100, Loss: 1.0949, Acc: 18.75%
    Iteration 120, Loss: 1.0906, Acc: 78.12%
    Iteration 140, Loss: 1.0991, Acc: 31.25%
    Iteration 160, Loss: 1.1016, Acc: 50.00%
    Iteration 180, Loss: 1.1009, Acc: 28.12%
    Iteration 200, Loss: 1.1025, Acc: 31.25%
    Iteration 220, Loss: 1.1044, Acc: 25.00%
    Iteration 240, Loss: 1.0896, Acc: 53.12%
    Iteration 260, Loss: 1.1038, Acc: 21.88%
    Iteration 280, Loss: 1.1147, Acc: 25.00%
    Iteration 300, Loss: 1.0983, Acc: 40.62%
    Iteration 320, Loss: 1.1033, Acc: 34.38%
    Iteration 340, Loss: 1.1148, Acc: 25.00%
    Iteration 360, Loss: 1.1137, Acc: 21.88%
    Iteration 380, Loss: 1.0930, Acc: 37.50%
    Iteration 400, Loss: 1.1004, Acc: 37.50%
    Iteration 420, Loss: 1.1002, Acc: 34.38%
Epoch 3 complete. Train Loss: 1.0972, Val Loss: 1.0980, Val Acc: 33.65%, Test Loss: 1.0981, Test Acc: 34.14%
  [*] New best val_acc = 0.3365
  [*] New best test_acc = 0.3414, saving model...
Epoch time: 58.17s

>>> Epoch 4/40
    Iteration 20, Loss: 1.1059, Acc: 34.38%
    Iteration 40, Loss: 1.0974, Acc: 37.50%
    Iteration 60, Loss: 1.1120, Acc: 25.00%
    Iteration 80, Loss: 1.1014, Acc: 21.88%
    Iteration 100, Loss: 1.1018, Acc: 37.50%
    Iteration 120, Loss: 1.0868, Acc: 78.12%
    Iteration 140, Loss: 1.0999, Acc: 37.50%
    Iteration 160, Loss: 1.1009, Acc: 46.88%
    Iteration 180, Loss: 1.0857, Acc: 50.00%
    Iteration 200, Loss: 1.0943, Acc: 43.75%
    Iteration 220, Loss: 1.1173, Acc: 21.88%
    Iteration 240, Loss: 1.0892, Acc: 46.88%
    Iteration 260, Loss: 1.1142, Acc: 9.38%
    Iteration 280, Loss: 1.0986, Acc: 28.12%
    Iteration 300, Loss: 1.0878, Acc: 46.88%
    Iteration 320, Loss: 1.1025, Acc: 34.38%
    Iteration 340, Loss: 1.0955, Acc: 25.00%
    Iteration 360, Loss: 1.0986, Acc: 18.75%
    Iteration 380, Loss: 1.0989, Acc: 25.00%
    Iteration 400, Loss: 1.0835, Acc: 43.75%
    Iteration 420, Loss: 1.1025, Acc: 21.88%
Epoch 4 complete. Train Loss: 1.0976, Val Loss: 1.0980, Val Acc: 32.60%, Test Loss: 1.0978, Test Acc: 33.88%
Epoch time: 57.85s

>>> Epoch 5/40
    Iteration 20, Loss: 1.0929, Acc: 37.50%
    Iteration 40, Loss: 1.1044, Acc: 37.50%
    Iteration 60, Loss: 1.1027, Acc: 21.88%
    Iteration 80, Loss: 1.1004, Acc: 34.38%
    Iteration 100, Loss: 1.1027, Acc: 31.25%
    Iteration 120, Loss: 1.1105, Acc: 78.12%
    Iteration 140, Loss: 1.0864, Acc: 46.88%
    Iteration 160, Loss: 1.1095, Acc: 34.38%
    Iteration 180, Loss: 1.1076, Acc: 25.00%
    Iteration 200, Loss: 1.1118, Acc: 21.88%
    Iteration 220, Loss: 1.0947, Acc: 40.62%
    Iteration 240, Loss: 1.0919, Acc: 37.50%
    Iteration 260, Loss: 1.1011, Acc: 31.25%
    Iteration 280, Loss: 1.0945, Acc: 40.62%
    Iteration 300, Loss: 1.0909, Acc: 37.50%
    Iteration 320, Loss: 1.1044, Acc: 43.75%
    Iteration 340, Loss: 1.0743, Acc: 34.38%
    Iteration 360, Loss: 1.0699, Acc: 34.38%
    Iteration 380, Loss: 1.0429, Acc: 43.75%
    Iteration 400, Loss: 1.1074, Acc: 31.25%
    Iteration 420, Loss: 1.0942, Acc: 37.50%
Epoch 5 complete. Train Loss: 1.0952, Val Loss: 1.1006, Val Acc: 30.98%, Test Loss: 1.0989, Test Acc: 31.43%
Epoch time: 57.92s

>>> Epoch 6/40
    Iteration 20, Loss: 1.0617, Acc: 50.00%
    Iteration 40, Loss: 1.0820, Acc: 37.50%
    Iteration 60, Loss: 1.0863, Acc: 31.25%
    Iteration 80, Loss: 1.1108, Acc: 28.12%
    Iteration 100, Loss: 1.0855, Acc: 34.38%
    Iteration 120, Loss: 1.0778, Acc: 37.50%
    Iteration 140, Loss: 1.1110, Acc: 37.50%
    Iteration 160, Loss: 1.0957, Acc: 37.50%
    Iteration 180, Loss: 1.0929, Acc: 31.25%
    Iteration 200, Loss: 1.0897, Acc: 43.75%
    Iteration 220, Loss: 1.1241, Acc: 28.12%
    Iteration 240, Loss: 1.0702, Acc: 37.50%
    Iteration 260, Loss: 1.0985, Acc: 28.12%
    Iteration 280, Loss: 1.0823, Acc: 43.75%
    Iteration 300, Loss: 1.0441, Acc: 37.50%
    Iteration 320, Loss: 1.0999, Acc: 40.62%
    Iteration 340, Loss: 1.0725, Acc: 34.38%
    Iteration 360, Loss: 1.0156, Acc: 37.50%
    Iteration 380, Loss: 0.9856, Acc: 50.00%
    Iteration 400, Loss: 1.0682, Acc: 34.38%
    Iteration 420, Loss: 1.0560, Acc: 43.75%
Epoch 6 complete. Train Loss: 1.0802, Val Loss: 1.1288, Val Acc: 25.47%, Test Loss: 1.1176, Test Acc: 28.12%
Epoch time: 55.96s

>>> Epoch 7/40
    Iteration 20, Loss: 1.1056, Acc: 31.25%
    Iteration 40, Loss: 1.0809, Acc: 25.00%
    Iteration 60, Loss: 1.0890, Acc: 34.38%
    Iteration 80, Loss: 1.0916, Acc: 40.62%
    Iteration 100, Loss: 1.0372, Acc: 46.88%
    Iteration 120, Loss: 1.1394, Acc: 15.62%
    Iteration 140, Loss: 1.1092, Acc: 28.12%
    Iteration 160, Loss: 1.0613, Acc: 46.88%
    Iteration 180, Loss: 1.0799, Acc: 40.62%
    Iteration 200, Loss: 1.0816, Acc: 46.88%
    Iteration 220, Loss: 1.0960, Acc: 34.38%
    Iteration 240, Loss: 1.0168, Acc: 56.25%
    Iteration 260, Loss: 1.0376, Acc: 40.62%
    Iteration 280, Loss: 1.0954, Acc: 40.62%
    Iteration 300, Loss: 1.0026, Acc: 40.62%
    Iteration 320, Loss: 1.0829, Acc: 37.50%
    Iteration 340, Loss: 1.0617, Acc: 34.38%
    Iteration 360, Loss: 0.9683, Acc: 40.62%
    Iteration 380, Loss: 0.9291, Acc: 50.00%
    Iteration 400, Loss: 1.0249, Acc: 46.88%
    Iteration 420, Loss: 1.0300, Acc: 40.62%
Epoch 7 complete. Train Loss: 1.0616, Val Loss: 1.1463, Val Acc: 26.57%, Test Loss: 1.1301, Test Acc: 29.55%
Epoch time: 57.72s

>>> Epoch 8/40
    Iteration 20, Loss: 1.1170, Acc: 28.12%
    Iteration 40, Loss: 1.0906, Acc: 21.88%
    Iteration 60, Loss: 1.0625, Acc: 40.62%
    Iteration 80, Loss: 1.1002, Acc: 31.25%
    Iteration 100, Loss: 1.0303, Acc: 37.50%
    Iteration 120, Loss: 1.0782, Acc: 15.62%
    Iteration 140, Loss: 1.1312, Acc: 25.00%
    Iteration 160, Loss: 1.0267, Acc: 43.75%
    Iteration 180, Loss: 1.0237, Acc: 43.75%
    Iteration 200, Loss: 1.1017, Acc: 31.25%
    Iteration 220, Loss: 1.0975, Acc: 28.12%
    Iteration 240, Loss: 0.9939, Acc: 37.50%
    Iteration 260, Loss: 1.0142, Acc: 43.75%
    Iteration 280, Loss: 1.0623, Acc: 50.00%
    Iteration 300, Loss: 1.0170, Acc: 40.62%
    Iteration 320, Loss: 1.0253, Acc: 46.88%
    Iteration 340, Loss: 1.0187, Acc: 43.75%
    Iteration 360, Loss: 0.9268, Acc: 50.00%
    Iteration 380, Loss: 0.9337, Acc: 53.12%
    Iteration 400, Loss: 1.0023, Acc: 46.88%
    Iteration 420, Loss: 1.0109, Acc: 46.88%
Epoch 8 complete. Train Loss: 1.0453, Val Loss: 1.1414, Val Acc: 27.88%, Test Loss: 1.1266, Test Acc: 30.58%
Epoch time: 57.85s

>>> Epoch 9/40
    Iteration 20, Loss: 1.1257, Acc: 28.12%
    Iteration 40, Loss: 1.0830, Acc: 28.12%
    Iteration 60, Loss: 1.0842, Acc: 34.38%
    Iteration 80, Loss: 1.0858, Acc: 37.50%
    Iteration 100, Loss: 1.0080, Acc: 46.88%
    Iteration 120, Loss: 1.0908, Acc: 12.50%
    Iteration 140, Loss: 1.1519, Acc: 21.88%
    Iteration 160, Loss: 1.0532, Acc: 37.50%
    Iteration 180, Loss: 0.9827, Acc: 43.75%
    Iteration 200, Loss: 1.0647, Acc: 31.25%
    Iteration 220, Loss: 1.0876, Acc: 40.62%
    Iteration 240, Loss: 0.9865, Acc: 37.50%
    Iteration 260, Loss: 1.0270, Acc: 40.62%
    Iteration 280, Loss: 1.0836, Acc: 46.88%
    Iteration 300, Loss: 1.0018, Acc: 37.50%
    Iteration 320, Loss: 1.0390, Acc: 43.75%
    Iteration 340, Loss: 0.9943, Acc: 56.25%
    Iteration 360, Loss: 0.9205, Acc: 56.25%
    Iteration 380, Loss: 0.9294, Acc: 62.50%
    Iteration 400, Loss: 1.0245, Acc: 50.00%
    Iteration 420, Loss: 0.9668, Acc: 62.50%
Epoch 9 complete. Train Loss: 1.0415, Val Loss: 1.1413, Val Acc: 27.83%, Test Loss: 1.1266, Test Acc: 30.41%
Epoch time: 57.96s

>>> Epoch 10/40
    Iteration 20, Loss: 1.1104, Acc: 40.62%
    Iteration 40, Loss: 1.0899, Acc: 31.25%
    Iteration 60, Loss: 1.0737, Acc: 43.75%
    Iteration 80, Loss: 1.0985, Acc: 28.12%
    Iteration 100, Loss: 1.0134, Acc: 46.88%
    Iteration 120, Loss: 1.0823, Acc: 18.75%
    Iteration 140, Loss: 1.1207, Acc: 31.25%
    Iteration 160, Loss: 1.0239, Acc: 46.88%
    Iteration 180, Loss: 1.0232, Acc: 34.38%
    Iteration 200, Loss: 1.0867, Acc: 34.38%
    Iteration 220, Loss: 1.0785, Acc: 31.25%
    Iteration 240, Loss: 0.9938, Acc: 37.50%
    Iteration 260, Loss: 1.0108, Acc: 43.75%
    Iteration 280, Loss: 1.0460, Acc: 50.00%
    Iteration 300, Loss: 1.0034, Acc: 43.75%
    Iteration 320, Loss: 1.0524, Acc: 50.00%
    Iteration 340, Loss: 0.9999, Acc: 46.88%
    Iteration 360, Loss: 0.9184, Acc: 56.25%
    Iteration 380, Loss: 0.9265, Acc: 50.00%
    Iteration 400, Loss: 1.0315, Acc: 43.75%
    Iteration 420, Loss: 0.9952, Acc: 46.88%
Epoch 10 complete. Train Loss: 1.0408, Val Loss: 1.1416, Val Acc: 27.83%, Test Loss: 1.1268, Test Acc: 30.81%
Epoch time: 57.89s

>>> Epoch 11/40
    Iteration 20, Loss: 1.1281, Acc: 28.12%
    Iteration 40, Loss: 1.0808, Acc: 28.12%
    Iteration 60, Loss: 1.0744, Acc: 34.38%
    Iteration 80, Loss: 1.1108, Acc: 21.88%
    Iteration 100, Loss: 1.0058, Acc: 43.75%
    Iteration 120, Loss: 1.0332, Acc: 18.75%
    Iteration 140, Loss: 1.1165, Acc: 25.00%
    Iteration 160, Loss: 1.0332, Acc: 37.50%
    Iteration 180, Loss: 1.0240, Acc: 34.38%
    Iteration 200, Loss: 1.0531, Acc: 34.38%
    Iteration 220, Loss: 1.0938, Acc: 37.50%
    Iteration 240, Loss: 0.9871, Acc: 40.62%
    Iteration 260, Loss: 0.9845, Acc: 37.50%
    Iteration 280, Loss: 1.0439, Acc: 62.50%
    Iteration 300, Loss: 1.0171, Acc: 31.25%
    Iteration 320, Loss: 1.0269, Acc: 53.12%
    Iteration 340, Loss: 1.0288, Acc: 46.88%
    Iteration 360, Loss: 0.9310, Acc: 53.12%
    Iteration 380, Loss: 0.9221, Acc: 56.25%
    Iteration 400, Loss: 1.0137, Acc: 50.00%
    Iteration 420, Loss: 0.9622, Acc: 65.62%
Epoch 11 complete. Train Loss: 1.0399, Val Loss: 1.1418, Val Acc: 28.02%, Test Loss: 1.1270, Test Acc: 30.75%
Epoch time: 55.62s

>>> Epoch 12/40
    Iteration 20, Loss: 1.1341, Acc: 31.25%
    Iteration 40, Loss: 1.0950, Acc: 28.12%
    Iteration 60, Loss: 1.0668, Acc: 40.62%
    Iteration 80, Loss: 1.1149, Acc: 28.12%
    Iteration 100, Loss: 1.0227, Acc: 40.62%
    Iteration 120, Loss: 1.0193, Acc: 15.62%
    Iteration 140, Loss: 1.1282, Acc: 25.00%
    Iteration 160, Loss: 1.0156, Acc: 43.75%
    Iteration 180, Loss: 1.0204, Acc: 37.50%
    Iteration 200, Loss: 1.0834, Acc: 31.25%
    Iteration 220, Loss: 1.0964, Acc: 37.50%
    Iteration 240, Loss: 0.9863, Acc: 40.62%
    Iteration 260, Loss: 1.0177, Acc: 40.62%
    Iteration 280, Loss: 1.0822, Acc: 43.75%
    Iteration 300, Loss: 0.9750, Acc: 50.00%
    Iteration 320, Loss: 1.0175, Acc: 53.12%
    Iteration 340, Loss: 0.9999, Acc: 46.88%
    Iteration 360, Loss: 0.9526, Acc: 50.00%
    Iteration 380, Loss: 0.9216, Acc: 53.12%
    Iteration 400, Loss: 1.0106, Acc: 50.00%
    Iteration 420, Loss: 0.9536, Acc: 56.25%
Epoch 12 complete. Train Loss: 1.0401, Val Loss: 1.1418, Val Acc: 27.96%, Test Loss: 1.1270, Test Acc: 30.75%
Epoch time: 57.85s

>>> Epoch 13/40
    Iteration 20, Loss: 1.0916, Acc: 34.38%
    Iteration 40, Loss: 1.0928, Acc: 25.00%
    Iteration 60, Loss: 1.0731, Acc: 40.62%
    Iteration 80, Loss: 1.1193, Acc: 21.88%
    Iteration 100, Loss: 0.9968, Acc: 53.12%
    Iteration 120, Loss: 1.0156, Acc: 15.62%
    Iteration 140, Loss: 1.1056, Acc: 28.12%
    Iteration 160, Loss: 1.0426, Acc: 37.50%
    Iteration 180, Loss: 1.0241, Acc: 34.38%
    Iteration 200, Loss: 1.0605, Acc: 31.25%
    Iteration 220, Loss: 1.0815, Acc: 34.38%
    Iteration 240, Loss: 0.9723, Acc: 53.12%
    Iteration 260, Loss: 1.0092, Acc: 43.75%
    Iteration 280, Loss: 1.0641, Acc: 46.88%
    Iteration 300, Loss: 1.0054, Acc: 40.62%
    Iteration 320, Loss: 1.0106, Acc: 50.00%
    Iteration 340, Loss: 1.0150, Acc: 43.75%
    Iteration 360, Loss: 0.9276, Acc: 50.00%
    Iteration 380, Loss: 0.9186, Acc: 53.12%
    Iteration 400, Loss: 0.9958, Acc: 53.12%
    Iteration 420, Loss: 1.0136, Acc: 53.12%
Epoch 13 complete. Train Loss: 1.0407, Val Loss: 1.1418, Val Acc: 27.96%, Test Loss: 1.1270, Test Acc: 30.75%
Epoch time: 59.58s

>>> Epoch 14/40
    Iteration 20, Loss: 1.1040, Acc: 34.38%
    Iteration 40, Loss: 1.0731, Acc: 28.12%
    Iteration 60, Loss: 1.0767, Acc: 31.25%
    Iteration 80, Loss: 1.0820, Acc: 40.62%
    Iteration 100, Loss: 0.9925, Acc: 56.25%
    Iteration 120, Loss: 1.0333, Acc: 18.75%
    Iteration 140, Loss: 1.1159, Acc: 25.00%
    Iteration 160, Loss: 1.0193, Acc: 37.50%
    Iteration 180, Loss: 1.0172, Acc: 34.38%
    Iteration 200, Loss: 1.0881, Acc: 31.25%
    Iteration 220, Loss: 1.0875, Acc: 37.50%
    Iteration 240, Loss: 0.9839, Acc: 37.50%
    Iteration 260, Loss: 0.9978, Acc: 37.50%
    Iteration 280, Loss: 1.0602, Acc: 46.88%
    Iteration 300, Loss: 1.0189, Acc: 37.50%
    Iteration 320, Loss: 1.0426, Acc: 40.62%
    Iteration 340, Loss: 1.0040, Acc: 46.88%
    Iteration 360, Loss: 0.9380, Acc: 50.00%
    Iteration 380, Loss: 0.9157, Acc: 56.25%
    Iteration 400, Loss: 0.9866, Acc: 56.25%
    Iteration 420, Loss: 1.0241, Acc: 46.88%
Epoch 14 complete. Train Loss: 1.0400, Val Loss: 1.1418, Val Acc: 27.89%, Test Loss: 1.1270, Test Acc: 30.75%
Epoch time: 57.88s

>>> Epoch 15/40
    Iteration 20, Loss: 1.1216, Acc: 31.25%
    Iteration 40, Loss: 1.0817, Acc: 25.00%
    Iteration 60, Loss: 1.0471, Acc: 40.62%
    Iteration 80, Loss: 1.0756, Acc: 43.75%
    Iteration 100, Loss: 0.9966, Acc: 53.12%
    Iteration 120, Loss: 1.0168, Acc: 21.88%
    Iteration 140, Loss: 1.1330, Acc: 21.88%
    Iteration 160, Loss: 0.9992, Acc: 43.75%
    Iteration 180, Loss: 1.0222, Acc: 46.88%
    Iteration 200, Loss: 1.0628, Acc: 31.25%
    Iteration 220, Loss: 1.1203, Acc: 31.25%
    Iteration 240, Loss: 0.9885, Acc: 46.88%
    Iteration 260, Loss: 0.9788, Acc: 31.25%
    Iteration 280, Loss: 1.0548, Acc: 50.00%
    Iteration 300, Loss: 1.0061, Acc: 34.38%
    Iteration 320, Loss: 1.0264, Acc: 53.12%
    Iteration 340, Loss: 1.0092, Acc: 56.25%
    Iteration 360, Loss: 0.9316, Acc: 50.00%
    Iteration 380, Loss: 0.9118, Acc: 56.25%
    Iteration 400, Loss: 1.0375, Acc: 56.25%
    Iteration 420, Loss: 1.0296, Acc: 46.88%
Epoch 15 complete. Train Loss: 1.0388, Val Loss: 1.1418, Val Acc: 27.89%, Test Loss: 1.1270, Test Acc: 30.75%
Epoch time: 56.13s

>>> Epoch 16/40
    Iteration 20, Loss: 1.1318, Acc: 31.25%
    Iteration 40, Loss: 1.0860, Acc: 25.00%
    Iteration 60, Loss: 1.0848, Acc: 37.50%
    Iteration 80, Loss: 1.0794, Acc: 46.88%
    Iteration 100, Loss: 1.0069, Acc: 43.75%
    Iteration 120, Loss: 1.0340, Acc: 9.38%
    Iteration 140, Loss: 1.0970, Acc: 37.50%
    Iteration 160, Loss: 1.0238, Acc: 37.50%
    Iteration 180, Loss: 1.0342, Acc: 34.38%
    Iteration 200, Loss: 1.0757, Acc: 34.38%
    Iteration 220, Loss: 1.0917, Acc: 37.50%
    Iteration 240, Loss: 0.9789, Acc: 28.12%
    Iteration 260, Loss: 1.0178, Acc: 46.88%
    Iteration 280, Loss: 1.0817, Acc: 50.00%
    Iteration 300, Loss: 1.0113, Acc: 43.75%
    Iteration 320, Loss: 1.0263, Acc: 53.12%
    Iteration 340, Loss: 1.0346, Acc: 40.62%
    Iteration 360, Loss: 0.9349, Acc: 43.75%
    Iteration 380, Loss: 0.9301, Acc: 53.12%
    Iteration 400, Loss: 1.0108, Acc: 62.50%
    Iteration 420, Loss: 0.9763, Acc: 56.25%
Epoch 16 complete. Train Loss: 1.0403, Val Loss: 1.1418, Val Acc: 27.89%, Test Loss: 1.1270, Test Acc: 30.75%
Epoch time: 57.54s

>>> Epoch 17/40
    Iteration 20, Loss: 1.1106, Acc: 31.25%
    Iteration 40, Loss: 1.0577, Acc: 34.38%
    Iteration 60, Loss: 1.0954, Acc: 43.75%
    Iteration 80, Loss: 1.1202, Acc: 28.12%
    Iteration 100, Loss: 1.0266, Acc: 43.75%
    Iteration 120, Loss: 1.0544, Acc: 15.62%
    Iteration 140, Loss: 1.1044, Acc: 34.38%
    Iteration 160, Loss: 1.0074, Acc: 50.00%
    Iteration 180, Loss: 1.0115, Acc: 40.62%
    Iteration 200, Loss: 1.0872, Acc: 31.25%
    Iteration 220, Loss: 1.0958, Acc: 40.62%
    Iteration 240, Loss: 0.9627, Acc: 37.50%
    Iteration 260, Loss: 1.0084, Acc: 40.62%
    Iteration 280, Loss: 1.0451, Acc: 65.62%
    Iteration 300, Loss: 0.9968, Acc: 43.75%
    Iteration 320, Loss: 1.0291, Acc: 43.75%
    Iteration 340, Loss: 1.0221, Acc: 40.62%
    Iteration 360, Loss: 0.9394, Acc: 46.88%
    Iteration 380, Loss: 0.9216, Acc: 46.88%
    Iteration 400, Loss: 1.0408, Acc: 46.88%
    Iteration 420, Loss: 0.9935, Acc: 59.38%
Epoch 17 complete. Train Loss: 1.0402, Val Loss: 1.1418, Val Acc: 27.89%, Test Loss: 1.1270, Test Acc: 30.75%
Epoch time: 57.87s

>>> Epoch 18/40
    Iteration 20, Loss: 1.1234, Acc: 28.12%
    Iteration 40, Loss: 1.0682, Acc: 37.50%
    Iteration 60, Loss: 1.0527, Acc: 50.00%
    Iteration 80, Loss: 1.0840, Acc: 37.50%
    Iteration 100, Loss: 1.0134, Acc: 43.75%
    Iteration 120, Loss: 1.0748, Acc: 15.62%
    Iteration 140, Loss: 1.1238, Acc: 34.38%
    Iteration 160, Loss: 1.0289, Acc: 40.62%
    Iteration 180, Loss: 1.0236, Acc: 28.12%
    Iteration 200, Loss: 1.0807, Acc: 31.25%
    Iteration 220, Loss: 1.0996, Acc: 31.25%
    Iteration 240, Loss: 0.9841, Acc: 37.50%
    Iteration 260, Loss: 0.9958, Acc: 40.62%
    Iteration 280, Loss: 1.0791, Acc: 53.12%
    Iteration 300, Loss: 1.0039, Acc: 34.38%
    Iteration 320, Loss: 1.0115, Acc: 50.00%
    Iteration 340, Loss: 1.0059, Acc: 50.00%
    Iteration 360, Loss: 0.9354, Acc: 46.88%
    Iteration 380, Loss: 0.9222, Acc: 46.88%
    Iteration 400, Loss: 1.0047, Acc: 56.25%
    Iteration 420, Loss: 1.0014, Acc: 56.25%
Epoch 18 complete. Train Loss: 1.0409, Val Loss: 1.1418, Val Acc: 27.89%, Test Loss: 1.1270, Test Acc: 30.75%
Epoch time: 57.94s

>>> Epoch 19/40
    Iteration 20, Loss: 1.0930, Acc: 40.62%
    Iteration 40, Loss: 1.0677, Acc: 28.12%
    Iteration 60, Loss: 1.0970, Acc: 31.25%
    Iteration 80, Loss: 1.0968, Acc: 28.12%
    Iteration 100, Loss: 1.0037, Acc: 53.12%
    Iteration 120, Loss: 1.0472, Acc: 21.88%
    Iteration 140, Loss: 1.0705, Acc: 37.50%
    Iteration 160, Loss: 1.0430, Acc: 46.88%
    Iteration 180, Loss: 1.0330, Acc: 34.38%
    Iteration 200, Loss: 1.0851, Acc: 34.38%
    Iteration 220, Loss: 1.0816, Acc: 34.38%
    Iteration 240, Loss: 0.9896, Acc: 40.62%
    Iteration 260, Loss: 0.9741, Acc: 40.62%
    Iteration 280, Loss: 1.0459, Acc: 50.00%
    Iteration 300, Loss: 0.9948, Acc: 40.62%
    Iteration 320, Loss: 1.0397, Acc: 46.88%
    Iteration 340, Loss: 1.0153, Acc: 46.88%
    Iteration 360, Loss: 0.9435, Acc: 53.12%
    Iteration 380, Loss: 0.9292, Acc: 53.12%
    Iteration 400, Loss: 1.0204, Acc: 46.88%
    Iteration 420, Loss: 0.9971, Acc: 46.88%
Epoch 19 complete. Train Loss: 1.0402, Val Loss: 1.1419, Val Acc: 27.83%, Test Loss: 1.1270, Test Acc: 30.75%
Epoch time: 56.42s

>>> Epoch 20/40
    Iteration 20, Loss: 1.0863, Acc: 43.75%
    Iteration 40, Loss: 1.0837, Acc: 28.12%
    Iteration 60, Loss: 1.0885, Acc: 37.50%
    Iteration 80, Loss: 1.1088, Acc: 37.50%
    Iteration 100, Loss: 1.0079, Acc: 59.38%
    Iteration 120, Loss: 1.0169, Acc: 15.62%
    Iteration 140, Loss: 1.1290, Acc: 25.00%
    Iteration 160, Loss: 1.0104, Acc: 50.00%
    Iteration 180, Loss: 1.0327, Acc: 31.25%
    Iteration 200, Loss: 1.0886, Acc: 37.50%
    Iteration 220, Loss: 1.0966, Acc: 31.25%
    Iteration 240, Loss: 0.9699, Acc: 37.50%
    Iteration 260, Loss: 1.0214, Acc: 31.25%
    Iteration 280, Loss: 1.0645, Acc: 46.88%
    Iteration 300, Loss: 1.0196, Acc: 46.88%
    Iteration 320, Loss: 1.0134, Acc: 59.38%
    Iteration 340, Loss: 1.0203, Acc: 50.00%
    Iteration 360, Loss: 0.9448, Acc: 46.88%
    Iteration 380, Loss: 0.9241, Acc: 46.88%
    Iteration 400, Loss: 0.9997, Acc: 56.25%
    Iteration 420, Loss: 1.0273, Acc: 46.88%
Epoch 20 complete. Train Loss: 1.0401, Val Loss: 1.1419, Val Acc: 27.83%, Test Loss: 1.1270, Test Acc: 30.75%
Epoch time: 57.32s

>>> Epoch 21/40
    Iteration 20, Loss: 1.1270, Acc: 31.25%
    Iteration 40, Loss: 1.0709, Acc: 31.25%
    Iteration 60, Loss: 1.0697, Acc: 37.50%
    Iteration 80, Loss: 1.1036, Acc: 40.62%
    Iteration 100, Loss: 1.0216, Acc: 46.88%
    Iteration 120, Loss: 1.0090, Acc: 9.38%
    Iteration 140, Loss: 1.1074, Acc: 34.38%
    Iteration 160, Loss: 1.0268, Acc: 37.50%
    Iteration 180, Loss: 1.0055, Acc: 43.75%
    Iteration 200, Loss: 1.0684, Acc: 34.38%
    Iteration 220, Loss: 1.0744, Acc: 37.50%
    Iteration 240, Loss: 0.9782, Acc: 50.00%
    Iteration 260, Loss: 0.9986, Acc: 40.62%
    Iteration 280, Loss: 1.0729, Acc: 46.88%
    Iteration 300, Loss: 0.9994, Acc: 43.75%
    Iteration 320, Loss: 1.0356, Acc: 56.25%
    Iteration 340, Loss: 0.9881, Acc: 53.12%
    Iteration 360, Loss: 0.9535, Acc: 46.88%
    Iteration 380, Loss: 0.9154, Acc: 50.00%
    Iteration 400, Loss: 0.9908, Acc: 56.25%
    Iteration 420, Loss: 0.9995, Acc: 59.38%
Epoch 21 complete. Train Loss: 1.0391, Val Loss: 1.1419, Val Acc: 27.83%, Test Loss: 1.1270, Test Acc: 30.75%
Epoch time: 57.82s

>>> Epoch 22/40
    Iteration 20, Loss: 1.1110, Acc: 25.00%
    Iteration 40, Loss: 1.0732, Acc: 37.50%
    Iteration 60, Loss: 1.0648, Acc: 34.38%
    Iteration 80, Loss: 1.0908, Acc: 34.38%
    Iteration 100, Loss: 1.0207, Acc: 46.88%
    Iteration 120, Loss: 1.0679, Acc: 12.50%
    Iteration 140, Loss: 1.1211, Acc: 25.00%
    Iteration 160, Loss: 1.0199, Acc: 50.00%
    Iteration 180, Loss: 1.0289, Acc: 37.50%
    Iteration 200, Loss: 1.0757, Acc: 37.50%
    Iteration 220, Loss: 1.0916, Acc: 40.62%
    Iteration 240, Loss: 1.0092, Acc: 31.25%
    Iteration 260, Loss: 0.9983, Acc: 43.75%
    Iteration 280, Loss: 1.0655, Acc: 43.75%
    Iteration 300, Loss: 0.9934, Acc: 34.38%
    Iteration 320, Loss: 1.0269, Acc: 50.00%
    Iteration 340, Loss: 1.0193, Acc: 40.62%
    Iteration 360, Loss: 0.9395, Acc: 50.00%
    Iteration 380, Loss: 0.9228, Acc: 56.25%
    Iteration 400, Loss: 1.0115, Acc: 59.38%
    Iteration 420, Loss: 0.9773, Acc: 56.25%
Epoch 22 complete. Train Loss: 1.0400, Val Loss: 1.1419, Val Acc: 27.83%, Test Loss: 1.1270, Test Acc: 30.75%
Epoch time: 57.92s

>>> Epoch 23/40
    Iteration 20, Loss: 1.0900, Acc: 37.50%
    Iteration 40, Loss: 1.0543, Acc: 37.50%
    Iteration 60, Loss: 1.0784, Acc: 43.75%
    Iteration 80, Loss: 1.0855, Acc: 37.50%
    Iteration 100, Loss: 0.9848, Acc: 56.25%
    Iteration 120, Loss: 1.0368, Acc: 18.75%
    Iteration 140, Loss: 1.1046, Acc: 31.25%
    Iteration 160, Loss: 1.0433, Acc: 37.50%
    Iteration 180, Loss: 1.0250, Acc: 31.25%
    Iteration 200, Loss: 1.0949, Acc: 34.38%
    Iteration 220, Loss: 1.0987, Acc: 31.25%
    Iteration 240, Loss: 0.9867, Acc: 43.75%
    Iteration 260, Loss: 0.9948, Acc: 34.38%
    Iteration 280, Loss: 1.0566, Acc: 43.75%
    Iteration 300, Loss: 0.9886, Acc: 34.38%
    Iteration 320, Loss: 1.0018, Acc: 56.25%
    Iteration 340, Loss: 1.0115, Acc: 46.88%
    Iteration 360, Loss: 0.9431, Acc: 46.88%
    Iteration 380, Loss: 0.9255, Acc: 46.88%
    Iteration 400, Loss: 1.0108, Acc: 50.00%
    Iteration 420, Loss: 1.0082, Acc: 46.88%
Epoch 23 complete. Train Loss: 1.0390, Val Loss: 1.1419, Val Acc: 27.83%, Test Loss: 1.1270, Test Acc: 30.75%
Epoch time: 57.79s

>>> Epoch 24/40
    Iteration 20, Loss: 1.1093, Acc: 34.38%
    Iteration 40, Loss: 1.0873, Acc: 21.88%
    Iteration 60, Loss: 1.0832, Acc: 40.62%
    Iteration 80, Loss: 1.0779, Acc: 40.62%
    Iteration 100, Loss: 0.9972, Acc: 50.00%
    Iteration 120, Loss: 1.0669, Acc: 15.62%
    Iteration 140, Loss: 1.1085, Acc: 25.00%
    Iteration 160, Loss: 1.0378, Acc: 43.75%
    Iteration 180, Loss: 1.0045, Acc: 34.38%
    Iteration 200, Loss: 1.1146, Acc: 25.00%
    Iteration 220, Loss: 1.1119, Acc: 28.12%
    Iteration 240, Loss: 1.0243, Acc: 34.38%
    Iteration 260, Loss: 1.0157, Acc: 37.50%
    Iteration 280, Loss: 1.0768, Acc: 53.12%
    Iteration 300, Loss: 0.9809, Acc: 46.88%
    Iteration 320, Loss: 1.0177, Acc: 46.88%
    Iteration 340, Loss: 1.0079, Acc: 53.12%
    Iteration 360, Loss: 0.9259, Acc: 46.88%
    Iteration 380, Loss: 0.9320, Acc: 53.12%
    Iteration 400, Loss: 1.0054, Acc: 53.12%
    Iteration 420, Loss: 1.0103, Acc: 43.75%
Epoch 24 complete. Train Loss: 1.0405, Val Loss: 1.1419, Val Acc: 27.83%, Test Loss: 1.1271, Test Acc: 30.75%
Epoch time: 55.92s

>>> Epoch 25/40
    Iteration 20, Loss: 1.1032, Acc: 28.12%
    Iteration 40, Loss: 1.0649, Acc: 34.38%
    Iteration 60, Loss: 1.0474, Acc: 40.62%
    Iteration 80, Loss: 1.0656, Acc: 50.00%
    Iteration 100, Loss: 0.9940, Acc: 43.75%
    Iteration 120, Loss: 1.0420, Acc: 15.62%
    Iteration 140, Loss: 1.1273, Acc: 31.25%
    Iteration 160, Loss: 1.0239, Acc: 37.50%
    Iteration 180, Loss: 1.0303, Acc: 37.50%
    Iteration 200, Loss: 1.0975, Acc: 34.38%
    Iteration 220, Loss: 1.0764, Acc: 40.62%
    Iteration 240, Loss: 0.9687, Acc: 37.50%
    Iteration 260, Loss: 1.0159, Acc: 34.38%
    Iteration 280, Loss: 1.0593, Acc: 43.75%
    Iteration 300, Loss: 1.0207, Acc: 40.62%
    Iteration 320, Loss: 1.0236, Acc: 53.12%
    Iteration 340, Loss: 1.0198, Acc: 46.88%
    Iteration 360, Loss: 0.9471, Acc: 50.00%
    Iteration 380, Loss: 0.9270, Acc: 53.12%
    Iteration 400, Loss: 0.9895, Acc: 56.25%
    Iteration 420, Loss: 0.9900, Acc: 53.12%
Epoch 25 complete. Train Loss: 1.0398, Val Loss: 1.1419, Val Acc: 27.83%, Test Loss: 1.1271, Test Acc: 30.75%
Epoch time: 58.01s

>>> Epoch 26/40
    Iteration 20, Loss: 1.1230, Acc: 37.50%
    Iteration 40, Loss: 1.0923, Acc: 31.25%
    Iteration 60, Loss: 1.1029, Acc: 31.25%
    Iteration 80, Loss: 1.0885, Acc: 28.12%
    Iteration 100, Loss: 0.9912, Acc: 46.88%
    Iteration 120, Loss: 1.0395, Acc: 18.75%
    Iteration 140, Loss: 1.1365, Acc: 21.88%
    Iteration 160, Loss: 1.0454, Acc: 37.50%
    Iteration 180, Loss: 1.0462, Acc: 28.12%
    Iteration 200, Loss: 1.0872, Acc: 31.25%
    Iteration 220, Loss: 1.0886, Acc: 37.50%
    Iteration 240, Loss: 0.9610, Acc: 50.00%
    Iteration 260, Loss: 1.0062, Acc: 37.50%
    Iteration 280, Loss: 1.0846, Acc: 40.62%
    Iteration 300, Loss: 1.0001, Acc: 43.75%
    Iteration 320, Loss: 1.0082, Acc: 43.75%
    Iteration 340, Loss: 1.0112, Acc: 46.88%
    Iteration 360, Loss: 0.9278, Acc: 56.25%
    Iteration 380, Loss: 0.9282, Acc: 50.00%
    Iteration 400, Loss: 1.0213, Acc: 53.12%
    Iteration 420, Loss: 1.0045, Acc: 46.88%
Epoch 26 complete. Train Loss: 1.0396, Val Loss: 1.1419, Val Acc: 27.83%, Test Loss: 1.1271, Test Acc: 30.75%
Epoch time: 58.01s

>>> Epoch 27/40
    Iteration 20, Loss: 1.0793, Acc: 31.25%
    Iteration 40, Loss: 1.0609, Acc: 25.00%
    Iteration 60, Loss: 1.0728, Acc: 40.62%
    Iteration 80, Loss: 1.0821, Acc: 40.62%
    Iteration 100, Loss: 1.0181, Acc: 40.62%
    Iteration 120, Loss: 1.0485, Acc: 12.50%
    Iteration 140, Loss: 1.1308, Acc: 31.25%
    Iteration 160, Loss: 1.0235, Acc: 34.38%
    Iteration 180, Loss: 0.9934, Acc: 40.62%
    Iteration 200, Loss: 1.0802, Acc: 31.25%
    Iteration 220, Loss: 1.0769, Acc: 34.38%
    Iteration 240, Loss: 0.9763, Acc: 40.62%
    Iteration 260, Loss: 1.0234, Acc: 37.50%
    Iteration 280, Loss: 1.0715, Acc: 50.00%
    Iteration 300, Loss: 1.0062, Acc: 43.75%
    Iteration 320, Loss: 1.0385, Acc: 46.88%
    Iteration 340, Loss: 1.0181, Acc: 53.12%
    Iteration 360, Loss: 0.9284, Acc: 46.88%
    Iteration 380, Loss: 0.9246, Acc: 56.25%
    Iteration 400, Loss: 1.0159, Acc: 50.00%
    Iteration 420, Loss: 1.0088, Acc: 46.88%
Epoch 27 complete. Train Loss: 1.0396, Val Loss: 1.1419, Val Acc: 27.83%, Test Loss: 1.1271, Test Acc: 30.75%
Epoch time: 58.04s

>>> Epoch 28/40
    Iteration 20, Loss: 1.1151, Acc: 37.50%
    Iteration 40, Loss: 1.0880, Acc: 28.12%
    Iteration 60, Loss: 1.0633, Acc: 50.00%
    Iteration 80, Loss: 1.0929, Acc: 31.25%
    Iteration 100, Loss: 0.9809, Acc: 50.00%
    Iteration 120, Loss: 1.0139, Acc: 15.62%
    Iteration 140, Loss: 1.1244, Acc: 28.12%
    Iteration 160, Loss: 1.0442, Acc: 43.75%
    Iteration 180, Loss: 1.0157, Acc: 40.62%
    Iteration 200, Loss: 1.0750, Acc: 34.38%
    Iteration 220, Loss: 1.0944, Acc: 31.25%
    Iteration 240, Loss: 0.9798, Acc: 40.62%
    Iteration 260, Loss: 1.0200, Acc: 37.50%
    Iteration 280, Loss: 1.0595, Acc: 50.00%
    Iteration 300, Loss: 0.9975, Acc: 40.62%
    Iteration 320, Loss: 1.0178, Acc: 46.88%
    Iteration 340, Loss: 1.0307, Acc: 46.88%
    Iteration 360, Loss: 0.9557, Acc: 50.00%
    Iteration 380, Loss: 0.9121, Acc: 46.88%
    Iteration 400, Loss: 1.0107, Acc: 53.12%
    Iteration 420, Loss: 1.0046, Acc: 56.25%
Epoch 28 complete. Train Loss: 1.0403, Val Loss: 1.1419, Val Acc: 27.70%, Test Loss: 1.1271, Test Acc: 30.75%
Epoch time: 55.95s

>>> Epoch 29/40
    Iteration 20, Loss: 1.1078, Acc: 31.25%
    Iteration 40, Loss: 1.0613, Acc: 37.50%
    Iteration 60, Loss: 1.0695, Acc: 40.62%
    Iteration 80, Loss: 1.0858, Acc: 37.50%
    Iteration 100, Loss: 1.0023, Acc: 43.75%
    Iteration 120, Loss: 1.0642, Acc: 18.75%
    Iteration 140, Loss: 1.1067, Acc: 37.50%
    Iteration 160, Loss: 1.0086, Acc: 40.62%
    Iteration 180, Loss: 1.0173, Acc: 31.25%
    Iteration 200, Loss: 1.0783, Acc: 37.50%
    Iteration 220, Loss: 1.0901, Acc: 37.50%
    Iteration 240, Loss: 0.9568, Acc: 46.88%
    Iteration 260, Loss: 1.0127, Acc: 37.50%
    Iteration 280, Loss: 1.0635, Acc: 43.75%
    Iteration 300, Loss: 1.0018, Acc: 37.50%
    Iteration 320, Loss: 1.0229, Acc: 50.00%
    Iteration 340, Loss: 1.0136, Acc: 46.88%
    Iteration 360, Loss: 0.9401, Acc: 50.00%
    Iteration 380, Loss: 0.9362, Acc: 46.88%
    Iteration 400, Loss: 1.0210, Acc: 50.00%
    Iteration 420, Loss: 0.9981, Acc: 53.12%
Epoch 29 complete. Train Loss: 1.0395, Val Loss: 1.1420, Val Acc: 27.57%, Test Loss: 1.1271, Test Acc: 30.75%
Epoch time: 57.96s

>>> Epoch 30/40
    Iteration 20, Loss: 1.1096, Acc: 25.00%
    Iteration 40, Loss: 1.0978, Acc: 25.00%
    Iteration 60, Loss: 1.0640, Acc: 40.62%
    Iteration 80, Loss: 1.0997, Acc: 34.38%
    Iteration 100, Loss: 1.0226, Acc: 43.75%
    Iteration 120, Loss: 1.0603, Acc: 21.88%
    Iteration 140, Loss: 1.1161, Acc: 34.38%
    Iteration 160, Loss: 1.0555, Acc: 40.62%
    Iteration 180, Loss: 1.0254, Acc: 37.50%
    Iteration 200, Loss: 1.0982, Acc: 31.25%
    Iteration 220, Loss: 1.1056, Acc: 31.25%
    Iteration 240, Loss: 0.9962, Acc: 43.75%
    Iteration 260, Loss: 1.0255, Acc: 34.38%
    Iteration 280, Loss: 1.0691, Acc: 46.88%
    Iteration 300, Loss: 1.0216, Acc: 37.50%
    Iteration 320, Loss: 1.0167, Acc: 56.25%
    Iteration 340, Loss: 0.9968, Acc: 50.00%
    Iteration 360, Loss: 0.9311, Acc: 46.88%
    Iteration 380, Loss: 0.9193, Acc: 46.88%
    Iteration 400, Loss: 1.0201, Acc: 46.88%
    Iteration 420, Loss: 0.9891, Acc: 59.38%
Epoch 30 complete. Train Loss: 1.0395, Val Loss: 1.1420, Val Acc: 27.63%, Test Loss: 1.1271, Test Acc: 30.75%
Epoch time: 57.85s

>>> Epoch 31/40
    Iteration 20, Loss: 1.0909, Acc: 31.25%
    Iteration 40, Loss: 1.0834, Acc: 28.12%
    Iteration 60, Loss: 1.0604, Acc: 40.62%
    Iteration 80, Loss: 1.1020, Acc: 31.25%
    Iteration 100, Loss: 1.0287, Acc: 40.62%
    Iteration 120, Loss: 1.1061, Acc: 12.50%
    Iteration 140, Loss: 1.1162, Acc: 28.12%
    Iteration 160, Loss: 1.0359, Acc: 46.88%
    Iteration 180, Loss: 1.0498, Acc: 43.75%
    Iteration 200, Loss: 1.0730, Acc: 34.38%
    Iteration 220, Loss: 1.0866, Acc: 40.62%
    Iteration 240, Loss: 0.9649, Acc: 50.00%
    Iteration 260, Loss: 0.9766, Acc: 37.50%
    Iteration 280, Loss: 1.0631, Acc: 53.12%
    Iteration 300, Loss: 1.0035, Acc: 50.00%
    Iteration 320, Loss: 1.0145, Acc: 43.75%
    Iteration 340, Loss: 1.0368, Acc: 37.50%
    Iteration 360, Loss: 0.9427, Acc: 53.12%
    Iteration 380, Loss: 0.9168, Acc: 53.12%
    Iteration 400, Loss: 1.0448, Acc: 46.88%
    Iteration 420, Loss: 0.9726, Acc: 59.38%
Epoch 31 complete. Train Loss: 1.0405, Val Loss: 1.1420, Val Acc: 27.63%, Test Loss: 1.1271, Test Acc: 30.64%
Epoch time: 57.87s

>>> Epoch 32/40
    Iteration 20, Loss: 1.1064, Acc: 34.38%
    Iteration 40, Loss: 1.0693, Acc: 34.38%
    Iteration 60, Loss: 1.0660, Acc: 40.62%
    Iteration 80, Loss: 1.1071, Acc: 37.50%
    Iteration 100, Loss: 1.0325, Acc: 37.50%
    Iteration 120, Loss: 1.0556, Acc: 18.75%
    Iteration 140, Loss: 1.1291, Acc: 31.25%
    Iteration 160, Loss: 1.0203, Acc: 43.75%
    Iteration 180, Loss: 1.0259, Acc: 37.50%
    Iteration 200, Loss: 1.0949, Acc: 28.12%
    Iteration 220, Loss: 1.1003, Acc: 34.38%
    Iteration 240, Loss: 0.9871, Acc: 40.62%
    Iteration 260, Loss: 1.0255, Acc: 34.38%
    Iteration 280, Loss: 1.0895, Acc: 46.88%
    Iteration 300, Loss: 1.0035, Acc: 40.62%
    Iteration 320, Loss: 1.0154, Acc: 53.12%
    Iteration 340, Loss: 0.9986, Acc: 50.00%
    Iteration 360, Loss: 0.9310, Acc: 46.88%
    Iteration 380, Loss: 0.9103, Acc: 46.88%
    Iteration 400, Loss: 1.0047, Acc: 53.12%
    Iteration 420, Loss: 1.0039, Acc: 43.75%
Epoch 32 complete. Train Loss: 1.0397, Val Loss: 1.1420, Val Acc: 27.63%, Test Loss: 1.1271, Test Acc: 30.64%
Epoch time: 57.56s

>>> Epoch 33/40
    Iteration 20, Loss: 1.1189, Acc: 28.12%
    Iteration 40, Loss: 1.0809, Acc: 34.38%
    Iteration 60, Loss: 1.0901, Acc: 34.38%
    Iteration 80, Loss: 1.0694, Acc: 46.88%
    Iteration 100, Loss: 1.0213, Acc: 37.50%
    Iteration 120, Loss: 1.0091, Acc: 15.62%
    Iteration 140, Loss: 1.1134, Acc: 28.12%
    Iteration 160, Loss: 1.0131, Acc: 43.75%
    Iteration 180, Loss: 0.9982, Acc: 40.62%
    Iteration 200, Loss: 1.0786, Acc: 34.38%
    Iteration 220, Loss: 1.0713, Acc: 40.62%
    Iteration 240, Loss: 0.9722, Acc: 43.75%
    Iteration 260, Loss: 1.0071, Acc: 31.25%
    Iteration 280, Loss: 1.0703, Acc: 43.75%
    Iteration 300, Loss: 0.9898, Acc: 40.62%
    Iteration 320, Loss: 1.0157, Acc: 53.12%
    Iteration 340, Loss: 1.0352, Acc: 40.62%
    Iteration 360, Loss: 0.9228, Acc: 50.00%
    Iteration 380, Loss: 0.9130, Acc: 53.12%
    Iteration 400, Loss: 0.9962, Acc: 53.12%
    Iteration 420, Loss: 1.0072, Acc: 56.25%
Epoch 33 complete. Train Loss: 1.0387, Val Loss: 1.1420, Val Acc: 27.70%, Test Loss: 1.1271, Test Acc: 30.70%
Epoch time: 56.21s

>>> Epoch 34/40
    Iteration 20, Loss: 1.1103, Acc: 34.38%
    Iteration 40, Loss: 1.0497, Acc: 34.38%
    Iteration 60, Loss: 1.0516, Acc: 46.88%
    Iteration 80, Loss: 1.0977, Acc: 40.62%
    Iteration 100, Loss: 0.9843, Acc: 53.12%
    Iteration 120, Loss: 1.0340, Acc: 12.50%
    Iteration 140, Loss: 1.1307, Acc: 25.00%
    Iteration 160, Loss: 1.0505, Acc: 37.50%
    Iteration 180, Loss: 1.0511, Acc: 40.62%
    Iteration 200, Loss: 1.0732, Acc: 31.25%
    Iteration 220, Loss: 1.1185, Acc: 31.25%
    Iteration 240, Loss: 0.9864, Acc: 43.75%
    Iteration 260, Loss: 1.0272, Acc: 34.38%
    Iteration 280, Loss: 1.0443, Acc: 43.75%
    Iteration 300, Loss: 0.9932, Acc: 40.62%
    Iteration 320, Loss: 1.0054, Acc: 56.25%
    Iteration 340, Loss: 1.0107, Acc: 46.88%
    Iteration 360, Loss: 0.9507, Acc: 43.75%
    Iteration 380, Loss: 0.9220, Acc: 53.12%
    Iteration 400, Loss: 0.9966, Acc: 53.12%
    Iteration 420, Loss: 0.9822, Acc: 56.25%
Epoch 34 complete. Train Loss: 1.0396, Val Loss: 1.1420, Val Acc: 27.70%, Test Loss: 1.1271, Test Acc: 30.70%
Epoch time: 57.89s

>>> Epoch 35/40
    Iteration 20, Loss: 1.1219, Acc: 31.25%
    Iteration 40, Loss: 1.0696, Acc: 34.38%
    Iteration 60, Loss: 1.0468, Acc: 50.00%
    Iteration 80, Loss: 1.1037, Acc: 31.25%
    Iteration 100, Loss: 1.0226, Acc: 50.00%
    Iteration 120, Loss: 1.0306, Acc: 15.62%
    Iteration 140, Loss: 1.1144, Acc: 28.12%
    Iteration 160, Loss: 1.0336, Acc: 46.88%
    Iteration 180, Loss: 1.0295, Acc: 37.50%
    Iteration 200, Loss: 1.0979, Acc: 31.25%
    Iteration 220, Loss: 1.0881, Acc: 40.62%
    Iteration 240, Loss: 0.9816, Acc: 50.00%
    Iteration 260, Loss: 0.9881, Acc: 31.25%
    Iteration 280, Loss: 1.0782, Acc: 40.62%
    Iteration 300, Loss: 1.0031, Acc: 40.62%
    Iteration 320, Loss: 1.0397, Acc: 53.12%
    Iteration 340, Loss: 1.0299, Acc: 40.62%
    Iteration 360, Loss: 0.9548, Acc: 40.62%
    Iteration 380, Loss: 0.9341, Acc: 46.88%
    Iteration 400, Loss: 1.0195, Acc: 50.00%
    Iteration 420, Loss: 0.9897, Acc: 56.25%
Epoch 35 complete. Train Loss: 1.0389, Val Loss: 1.1420, Val Acc: 27.70%, Test Loss: 1.1271, Test Acc: 30.70%
Epoch time: 56.39s

>>> Epoch 36/40
    Iteration 20, Loss: 1.1104, Acc: 28.12%
    Iteration 40, Loss: 1.0806, Acc: 21.88%
    Iteration 60, Loss: 1.0552, Acc: 40.62%
    Iteration 80, Loss: 1.0904, Acc: 46.88%
    Iteration 100, Loss: 1.0227, Acc: 50.00%
    Iteration 120, Loss: 1.0414, Acc: 15.62%
    Iteration 140, Loss: 1.1164, Acc: 28.12%
    Iteration 160, Loss: 1.0443, Acc: 46.88%
    Iteration 180, Loss: 1.0059, Acc: 37.50%
    Iteration 200, Loss: 1.0691, Acc: 37.50%
    Iteration 220, Loss: 1.0765, Acc: 40.62%
    Iteration 240, Loss: 0.9930, Acc: 43.75%
    Iteration 260, Loss: 0.9987, Acc: 37.50%
    Iteration 280, Loss: 1.0679, Acc: 43.75%
    Iteration 300, Loss: 1.0084, Acc: 34.38%
    Iteration 320, Loss: 1.0450, Acc: 50.00%
    Iteration 340, Loss: 1.0164, Acc: 40.62%
    Iteration 360, Loss: 0.9234, Acc: 50.00%
    Iteration 380, Loss: 0.9164, Acc: 59.38%
    Iteration 400, Loss: 1.0154, Acc: 56.25%
    Iteration 420, Loss: 0.9867, Acc: 53.12%
Epoch 36 complete. Train Loss: 1.0389, Val Loss: 1.1420, Val Acc: 27.76%, Test Loss: 1.1272, Test Acc: 30.64%
Epoch time: 58.16s

>>> Epoch 37/40
    Iteration 20, Loss: 1.1175, Acc: 37.50%
    Iteration 40, Loss: 1.0684, Acc: 34.38%
    Iteration 60, Loss: 1.0916, Acc: 34.38%
    Iteration 80, Loss: 1.0974, Acc: 43.75%
    Iteration 100, Loss: 1.0012, Acc: 50.00%
    Iteration 120, Loss: 1.0891, Acc: 15.62%
    Iteration 140, Loss: 1.1186, Acc: 28.12%
    Iteration 160, Loss: 1.0245, Acc: 46.88%
    Iteration 180, Loss: 1.0413, Acc: 37.50%
    Iteration 200, Loss: 1.0864, Acc: 40.62%
    Iteration 220, Loss: 1.0964, Acc: 40.62%
    Iteration 240, Loss: 0.9881, Acc: 31.25%
    Iteration 260, Loss: 1.0061, Acc: 37.50%
    Iteration 280, Loss: 1.0747, Acc: 53.12%
    Iteration 300, Loss: 1.0012, Acc: 34.38%
    Iteration 320, Loss: 1.0060, Acc: 46.88%
    Iteration 340, Loss: 1.0110, Acc: 50.00%
    Iteration 360, Loss: 0.9345, Acc: 46.88%
    Iteration 380, Loss: 0.9224, Acc: 50.00%
    Iteration 400, Loss: 1.0149, Acc: 50.00%
    Iteration 420, Loss: 0.9797, Acc: 59.38%
Epoch 37 complete. Train Loss: 1.0398, Val Loss: 1.1420, Val Acc: 27.76%, Test Loss: 1.1272, Test Acc: 30.64%
Epoch time: 57.85s

>>> Epoch 38/40
    Iteration 20, Loss: 1.1291, Acc: 28.12%
    Iteration 40, Loss: 1.0924, Acc: 34.38%
    Iteration 60, Loss: 1.0660, Acc: 40.62%
    Iteration 80, Loss: 1.0923, Acc: 43.75%
    Iteration 100, Loss: 1.0119, Acc: 50.00%
    Iteration 120, Loss: 1.0654, Acc: 15.62%
    Iteration 140, Loss: 1.1270, Acc: 18.75%
    Iteration 160, Loss: 1.0187, Acc: 40.62%
    Iteration 180, Loss: 1.0067, Acc: 40.62%
    Iteration 200, Loss: 1.0688, Acc: 28.12%
    Iteration 220, Loss: 1.0907, Acc: 37.50%
    Iteration 240, Loss: 0.9804, Acc: 46.88%
    Iteration 260, Loss: 1.0009, Acc: 40.62%
    Iteration 280, Loss: 1.0840, Acc: 50.00%
    Iteration 300, Loss: 1.0010, Acc: 46.88%
    Iteration 320, Loss: 1.0279, Acc: 46.88%
    Iteration 340, Loss: 1.0280, Acc: 43.75%
    Iteration 360, Loss: 0.9269, Acc: 46.88%
    Iteration 380, Loss: 0.9103, Acc: 56.25%
    Iteration 400, Loss: 1.0113, Acc: 46.88%
    Iteration 420, Loss: 0.9804, Acc: 56.25%
Epoch 38 complete. Train Loss: 1.0391, Val Loss: 1.1420, Val Acc: 27.76%, Test Loss: 1.1272, Test Acc: 30.64%
Epoch time: 60.98s

>>> Epoch 39/40
    Iteration 20, Loss: 1.1164, Acc: 34.38%
    Iteration 40, Loss: 1.0965, Acc: 31.25%
    Iteration 60, Loss: 1.0882, Acc: 31.25%
    Iteration 80, Loss: 1.1285, Acc: 40.62%
    Iteration 100, Loss: 1.0223, Acc: 59.38%
    Iteration 120, Loss: 1.0607, Acc: 15.62%
    Iteration 140, Loss: 1.1105, Acc: 31.25%
    Iteration 160, Loss: 1.0639, Acc: 40.62%
    Iteration 180, Loss: 1.0273, Acc: 37.50%
    Iteration 200, Loss: 1.1016, Acc: 28.12%
    Iteration 220, Loss: 1.1015, Acc: 31.25%
    Iteration 240, Loss: 0.9718, Acc: 46.88%
    Iteration 260, Loss: 0.9984, Acc: 31.25%
    Iteration 280, Loss: 1.0520, Acc: 56.25%
    Iteration 300, Loss: 1.0070, Acc: 40.62%
    Iteration 320, Loss: 1.0252, Acc: 46.88%
    Iteration 340, Loss: 1.0272, Acc: 43.75%
    Iteration 360, Loss: 0.9349, Acc: 56.25%
    Iteration 380, Loss: 0.9432, Acc: 50.00%
    Iteration 400, Loss: 1.0083, Acc: 46.88%
    Iteration 420, Loss: 1.0042, Acc: 46.88%
Epoch 39 complete. Train Loss: 1.0400, Val Loss: 1.1421, Val Acc: 27.83%, Test Loss: 1.1272, Test Acc: 30.64%
Epoch time: 60.48s

>>> Epoch 40/40
    Iteration 20, Loss: 1.0924, Acc: 31.25%
    Iteration 40, Loss: 1.0535, Acc: 40.62%
    Iteration 60, Loss: 1.0626, Acc: 40.62%
    Iteration 80, Loss: 1.0992, Acc: 31.25%
    Iteration 100, Loss: 1.0191, Acc: 50.00%
    Iteration 120, Loss: 1.0644, Acc: 18.75%
    Iteration 140, Loss: 1.1053, Acc: 31.25%
    Iteration 160, Loss: 1.0075, Acc: 50.00%
    Iteration 180, Loss: 1.0251, Acc: 34.38%
    Iteration 200, Loss: 1.0770, Acc: 34.38%
    Iteration 220, Loss: 1.0862, Acc: 40.62%
    Iteration 240, Loss: 0.9943, Acc: 43.75%
    Iteration 260, Loss: 0.9791, Acc: 46.88%
    Iteration 280, Loss: 1.0710, Acc: 46.88%
    Iteration 300, Loss: 1.0078, Acc: 40.62%
    Iteration 320, Loss: 1.0311, Acc: 46.88%
    Iteration 340, Loss: 0.9820, Acc: 53.12%
    Iteration 360, Loss: 0.9285, Acc: 43.75%
    Iteration 380, Loss: 0.9176, Acc: 46.88%
    Iteration 400, Loss: 1.0125, Acc: 50.00%
    Iteration 420, Loss: 0.9904, Acc: 56.25%
Epoch 40 complete. Train Loss: 1.0393, Val Loss: 1.1421, Val Acc: 27.89%, Test Loss: 1.1272, Test Acc: 30.64%
Epoch time: 58.25s
Train/val/test loss curve saved to /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/MOASC2/2025-03-06/sub-1/009_Mar-06-2025_09:40_PM/train_val_test_loss_curve.png
Confusion matrix saved to /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/MOASC2/2025-03-06/sub-1/009_Mar-06-2025_09:40_PM/confusion_matrix.png

Done. Logs and plots should be in: /home/rgg2706/Multimodal-Sentiment-Analysis/Logs/MOASC2/2025-03-06/sub-1/009_Mar-06-2025_09:40_PM
